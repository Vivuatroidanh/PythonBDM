{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stroke Prediction: Model Explainability with SHAP\n",
    "\n",
    "This notebook focuses on explaining the stroke prediction model using SHAP (SHapley Additive exPlanations):\n",
    "1. Loading the trained model and preprocessed data\n",
    "2. Understanding the SHAP framework for explainability\n",
    "3. Generating global feature importance explanations\n",
    "4. Creating local explanations for individual predictions\n",
    "5. Visualizing feature interactions and their effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# SHAP explainer library\n",
    "import shap\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "sns.set_style('whitegrid')\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create directories for outputs\n",
    "os.makedirs('figures/shap_explanations', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model, scaler, and metadata\n",
    "def load_model_assets(model_path='models/stroke_prediction_model.pkl',\n",
    "                      scaler_path='models/stroke_prediction_scaler.pkl',\n",
    "                      metadata_path='models/stroke_prediction_metadata.json'):\n",
    "    \"\"\"\n",
    "    Load the saved model, scaler, and metadata.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        model, scaler, metadata\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    print(f\"Loaded model from {model_path}\")\n",
    "    \n",
    "    # Load scaler\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    print(f\"Loaded scaler from {scaler_path}\")\n",
    "    \n",
    "    # Load metadata\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    print(f\"Loaded metadata from {metadata_path}\")\n",
    "    \n",
    "    return model, scaler, metadata\n",
    "\n",
    "# Load model assets\n",
    "model, scaler, metadata = load_model_assets()\n",
    "\n",
    "# Display model metadata\n",
    "print(\"\\nModel Metadata:\")\n",
    "print(f\"Model name: {metadata['model_name']}\")\n",
    "print(f\"Number of features: {metadata['num_features']}\")\n",
    "print(\"\\nTest metrics:\")\n",
    "for metric, value in metadata['test_metrics'].items():\n",
    "    if value is not None:  # Some metrics might be None\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "print(\"\\nClass distribution:\")\n",
    "print(f\"  Negative (No Stroke): {metadata['class_distribution']['negative']}\")\n",
    "print(f\"  Positive (Stroke): {metadata['class_distribution']['positive']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data for SHAP analysis\n",
    "# We'll use the encoded dataset to match the model's input format\n",
    "df = pd.read_csv('data/processed/stroke_dataset_encoded.csv')\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert scaled data back to DataFrames with feature names\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "print(f\"Data loaded and prepared: {X_train.shape[0]} training samples, {X_test.shape[0]} test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also load the unencoded dataset for more interpretable feature names\n",
    "df_interpretable = pd.read_csv('data/processed/stroke_dataset_eda.csv')\n",
    "\n",
    "# Create a mapping of feature names\n",
    "feature_mapping = {}\n",
    "for col in X.columns:\n",
    "    # For one-hot encoded columns, extract the original feature name and value\n",
    "    if '_' in col:\n",
    "        parts = col.split('_')\n",
    "        if parts[-1].isdigit():  # For numbered categories\n",
    "            feature = '_'.join(parts[:-1])\n",
    "            value = parts[-1]\n",
    "            feature_mapping[col] = f\"{feature} = {value}\"\n",
    "        else:  # For string categories\n",
    "            feature = parts[0]\n",
    "            value = '_'.join(parts[1:])\n",
    "            feature_mapping[col] = f\"{feature} = {value}\"\n",
    "    else:\n",
    "        # For non-encoded columns, use the original name\n",
    "        feature_mapping[col] = col\n",
    "        \n",
    "print(\"Sample of feature mapping for better interpretability:\")\n",
    "for i, (orig, interp) in enumerate(list(feature_mapping.items())[:10]):\n",
    "    print(f\"{orig} â†’ {interp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding SHAP Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Introduction to SHAP\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) is a unified approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions.\n",
    "\n",
    "Key features of SHAP:\n",
    "- **Global interpretability**: Understand which features are most important for the model overall\n",
    "- **Local interpretability**: Explain individual predictions, showing how each feature contributes\n",
    "- **Model-agnostic**: Works with any machine learning model\n",
    "- **Solid theoretical foundation**: Based on Shapley values from cooperative game theory\n",
    "\n",
    "SHAP values represent the contribution of each feature to the prediction, compared to the average prediction. A positive SHAP value means the feature increased the predicted probability of stroke, while a negative value means it decreased it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Setting Up the SHAP Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create appropriate SHAP explainer based on model type\n",
    "def create_shap_explainer(model):\n",
    "    \"\"\"\n",
    "    Create an appropriate SHAP explainer based on the model type.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : model object\n",
    "        The trained model\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    shap.Explainer\n",
    "        The appropriate SHAP explainer\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if it's an ensemble model (StackingClassifier or VotingClassifier)\n",
    "        if hasattr(model, 'estimators_') and hasattr(model, 'final_estimator_'):  # StackingClassifier\n",
    "            print(\"Detected StackingClassifier, using Kernel explainer on meta-estimator...\")\n",
    "            # Use the final estimator for SHAP\n",
    "            meta_estimator = model.final_estimator_\n",
    "            if hasattr(meta_estimator, 'feature_importances_') or hasattr(meta_estimator, 'coef_'):\n",
    "                # For tree-based or linear meta-estimators\n",
    "                return shap.Explainer(meta_estimator)\n",
    "            else:\n",
    "                # For other meta-estimators, use KernelExplainer\n",
    "                # Create background dataset\n",
    "                background_data = shap.sample(X_train_scaled_df, 100)  # Sample 100 background examples\n",
    "                return shap.KernelExplainer(model.predict_proba, background_data)\n",
    "        \n",
    "        elif hasattr(model, 'estimators_') and hasattr(model, 'weights'):  # VotingClassifier\n",
    "            print(\"Detected VotingClassifier, using KernelExplainer...\")\n",
    "            # For VotingClassifier, use KernelExplainer\n",
    "            background_data = shap.sample(X_train_scaled_df, 100)  # Sample 100 background examples\n",
    "            return shap.KernelExplainer(model.predict_proba, background_data)\n",
    "        \n",
    "        # Check if it's a tree-based model\n",
    "        elif hasattr(model, 'feature_importances_'):\n",
    "            print(\"Detected tree-based model, using TreeExplainer...\")\n",
    "            # For tree-based models (RandomForest, XGBoost, etc.)\n",
    "            return shap.TreeExplainer(model)\n",
    "        \n",
    "        # Check if it's a linear model\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            print(\"Detected linear model, using LinearExplainer...\")\n",
    "            # For linear models (LogisticRegression, etc.)\n",
    "            return shap.LinearExplainer(model, X_train_scaled_df)\n",
    "        \n",
    "        else:\n",
    "            print(\"Model type not specifically supported, using Kernel explainer...\")\n",
    "            # For all other model types, use KernelExplainer\n",
    "            background_data = shap.sample(X_train_scaled_df, 100)  # Sample 100 background examples\n",
    "            return shap.KernelExplainer(model.predict_proba, background_data)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating SHAP explainer: {e}\")\n",
    "        print(\"Falling back to Kernel explainer...\")\n",
    "        # Fallback to KernelExplainer\n",
    "        background_data = shap.sample(X_train_scaled_df, 100)  # Sample 100 background examples\n",
    "        return shap.KernelExplainer(model.predict_proba, background_data)\n",
    "\n",
    "# Create SHAP explainer\n",
    "print(\"Creating SHAP explainer...\")\n",
    "explainer = create_shap_explainer(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Global Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values for a sample of the test set to speed up computation\n",
    "print(\"Calculating SHAP values for a sample of the test set...\")\n",
    "sample_size = min(100, X_test_scaled_df.shape[0])  # Use at most 100 samples\n",
    "sample_indices = np.random.choice(X_test_scaled_df.shape[0], sample_size, replace=False)\n",
    "X_sample = X_test_scaled_df.iloc[sample_indices]\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "# Extract values for positive class (stroke=1)\n",
    "if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "    shap_values_class1 = shap_values[1]  # For binary classification, second element is for class 1\n",
    "else:\n",
    "    shap_values_class1 = shap_values\n",
    "\n",
    "print(f\"SHAP values calculated for {sample_size} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary plot of SHAP values\n",
    "plt.figure(figsize=(14, 10))\n",
    "shap.summary_plot(shap_values_class1, X_sample, max_display=20, show=False)\n",
    "plt.title(\"Feature Importance (Impact on Stroke Prediction)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/shap_explanations/global_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create a bar plot of mean absolute SHAP values\n",
    "plt.figure(figsize=(14, 10))\n",
    "shap.summary_plot(shap_values_class1, X_sample, plot_type=\"bar\", max_display=20, show=False)\n",
    "plt.title(\"Feature Importance (Mean Absolute SHAP Values)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/shap_explanations/global_feature_importance_bar.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display mean absolute SHAP values for each feature\n",
    "mean_abs_shap = np.abs(shap_values_class1).mean(0)\n",
    "\n",
    "# Create DataFrame with feature names and SHAP values\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_sample.columns,\n",
    "    'SHAP Importance': mean_abs_shap\n",
    "})\n",
    "\n",
    "# Add interpretable feature names\n",
    "feature_importance['Interpretable Name'] = feature_importance['Feature'].map(feature_mapping)\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance = feature_importance.sort_values('SHAP Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display top 20 features\n",
    "print(\"Top 20 features by importance (mean absolute SHAP value):\")\n",
    "feature_importance.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Interactions and Dependence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 5 most important features\n",
    "top_features = feature_importance['Feature'].head(5).tolist()\n",
    "print(f\"Top 5 features: {top_features}\")\n",
    "\n",
    "# Create dependence plots for each top feature\n",
    "for feature in top_features:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.dependence_plot(\n",
    "        feature, shap_values_class1, X_sample,\n",
    "        interaction_index=None,  # Auto-detect interaction\n",
    "        show=False\n",
    "    )\n",
    "    interpretable_name = feature_mapping.get(feature, feature)\n",
    "    plt.title(f\"Dependence Plot: {interpretable_name}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/shap_explanations/dependence_{feature.replace(\" \", \"_\")}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interaction plots for the top 3 features\n",
    "# Try to find the strongest interaction for each feature\n",
    "for i, feature in enumerate(top_features[:3]):\n",
    "    # Find potential interaction features (excluding the feature itself)\n",
    "    potential_interactions = [f for f in top_features if f != feature]\n",
    "    \n",
    "    # Plot with the first potential interaction feature\n",
    "    interaction_feature = potential_interactions[0]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.dependence_plot(\n",
    "        feature, shap_values_class1, X_sample,\n",
    "        interaction_index=interaction_feature,\n",
    "        show=False\n",
    "    )\n",
    "    \n",
    "    interpretable_name1 = feature_mapping.get(feature, feature)\n",
    "    interpretable_name2 = feature_mapping.get(interaction_feature, interaction_feature)\n",
    "    plt.title(f\"Interaction: {interpretable_name1} vs {interpretable_name2}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/shap_explanations/interaction_{feature}_{interaction_feature}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Local Explanations for Individual Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to explain individual predictions\n",
    "def explain_prediction(instance_idx, X_data, y_data, explainer, feature_mapping=None):\n",
    "    \"\"\"\n",
    "    Explain an individual prediction with SHAP.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    instance_idx : int\n",
    "        Index of the instance to explain\n",
    "    X_data : pd.DataFrame\n",
    "        Features dataframe\n",
    "    y_data : pd.Series\n",
    "        Target series\n",
    "    explainer : shap.Explainer\n",
    "        SHAP explainer\n",
    "    feature_mapping : dict, optional\n",
    "        Mapping of feature names to interpretable names\n",
    "    \"\"\"\n",
    "    # Get the instance\n",
    "    instance = X_data.iloc[[instance_idx]]\n",
    "    true_label = y_data.iloc[instance_idx]\n",
    "    \n",
    "    # Get prediction\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        prediction_proba = model.predict_proba(instance)[0, 1]\n",
    "        prediction = int(prediction_proba >= 0.5)\n",
    "    else:\n",
    "        prediction = model.predict(instance)[0]\n",
    "        prediction_proba = None\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    instance_shap_values = explainer.shap_values(instance)\n",
    "    if isinstance(instance_shap_values, list) and len(instance_shap_values) > 1:\n",
    "        # For classifiers that return a list of SHAP values per class\n",
    "        instance_shap_class1 = instance_shap_values[1]\n",
    "        expected_value = explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value\n",
    "    else:\n",
    "        # For other models\n",
    "        instance_shap_class1 = instance_shap_values\n",
    "        expected_value = explainer.expected_value\n",
    "    \n",
    "    # Display prediction information\n",
    "    print(f\"Instance Index: {instance_idx}\")\n",
    "    print(f\"True Label: {'Stroke' if true_label == 1 else 'No Stroke'} ({true_label})\")\n",
    "    print(f\"Predicted Label: {'Stroke' if prediction == 1 else 'No Stroke'} ({prediction})\")\n",
    "    if prediction_proba is not None:\n",
    "        print(f\"Predicted Probability: {prediction_proba:.4f}\")\n",
    "    print(f\"Prediction: {'Correct' if prediction == true_label else 'Incorrect'}\")\n",
    "    \n",
    "    # Display key feature values\n",
    "    print(\"\\nKey Feature Values:\")\n",
    "    for feature in top_features[:5]:  # Display top 5 important features\n",
    "        interpretable_name = feature_mapping.get(feature, feature) if feature_mapping else feature\n",
    "        value = instance[feature].values[0]\n",
    "        print(f\"  {interpretable_name}: {value:.4f}\")\n",
    "    \n",
    "    # Create force plot\n",
    "    plt.figure(figsize=(20, 3))\n",
    "    force_plot = shap.force_plot(expected_value, instance_shap_class1[0], instance.iloc[0], \n",
    "                                feature_names=instance.columns.tolist(),\n",
    "                                matplotlib=True, show=False)\n",
    "    plt.title(f\"SHAP Force Plot - Instance {instance_idx}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/shap_explanations/force_plot_instance_{instance_idx}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Create waterfall plot\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    shap.plots._waterfall.waterfall_legacy(\n",
    "        expected_value, instance_shap_class1[0], \n",
    "        feature_names=instance.columns.tolist(),\n",
    "        max_display=10, show=False\n",
    "    )\n",
    "    plt.title(f\"SHAP Waterfall Plot - Instance {instance_idx}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/shap_explanations/waterfall_plot_instance_{instance_idx}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Create decision plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    shap.decision_plot(expected_value, instance_shap_class1[0], \n",
    "                      instance.iloc[0], feature_names=instance.columns.tolist(),\n",
    "                      feature_display_range=slice(-1, -10, -1),\n",
    "                      show=False)\n",
    "    plt.title(f\"SHAP Decision Plot - Instance {instance_idx}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/shap_explanations/decision_plot_instance_{instance_idx}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Return the SHAP values and expected value for further analysis\n",
    "    return {\n",
    "        'instance': instance,\n",
    "        'true_label': true_label,\n",
    "        'prediction': prediction,\n",
    "        'prediction_proba': prediction_proba,\n",
    "        'shap_values': instance_shap_class1,\n",
    "        'expected_value': expected_value\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select some interesting instances to explain\n",
    "# 1. Find a true positive (correctly predicted stroke)\n",
    "# 2. Find a true negative (correctly predicted no stroke)\n",
    "# 3. Find a false positive (incorrectly predicted stroke)\n",
    "# 4. Find a false negative (incorrectly predicted no stroke)\n",
    "\n",
    "# Get predictions on test set\n",
    "y_pred = model.predict(X_test_scaled_df)\n",
    "try:\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled_df)[:, 1]\n",
    "except:\n",
    "    y_pred_proba = None\n",
    "\n",
    "# Find indices for each case\n",
    "true_positive_indices = np.where((y_test == 1) & (y_pred == 1))[0]\n",
    "true_negative_indices = np.where((y_test == 0) & (y_pred == 0))[0]\n",
    "false_positive_indices = np.where((y_test == 0) & (y_pred == 1))[0]\n",
    "false_negative_indices = np.where((y_test == 1) & (y_pred == 0))[0]\n",
    "\n",
    "print(f\"True Positives: {len(true_positive_indices)}\")\n",
    "print(f\"True Negatives: {len(true_negative_indices)}\")\n",
    "print(f\"False Positives: {len(false_positive_indices)}\")\n",
    "print(f\"False Negatives: {len(false_negative_indices)}\")\n",
    "\n",
    "# Select one instance from each category (if available)\n",
    "instances_to_explain = []\n",
    "\n",
    "if len(true_positive_indices) > 0:\n",
    "    instances_to_explain.append((true_positive_indices[0], \"True Positive\"))\n",
    "    \n",
    "if len(true_negative_indices) > 0:\n",
    "    instances_to_explain.append((true_negative_indices[0], \"True Negative\"))\n",
    "    \n",
    "if len(false_positive_indices) > 0:\n",
    "    instances_to_explain.append((false_positive_indices[0], \"False Positive\"))\n",
    "    \n",
    "if len(false_negative_indices) > 0:\n",
    "    instances_to_explain.append((false_negative_indices[0], \"False Negative\"))\n",
    "\n",
    "print(f\"\\nSelected {len(instances_to_explain)} instances to explain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain each selected instance\n",
    "explanations = {}\n",
    "\n",
    "for idx, case_type in instances_to_explain:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Explaining {case_type} (Instance {idx})\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    explanation = explain_prediction(\n",
    "        idx, X_test_scaled_df, y_test, \n",
    "        explainer, feature_mapping\n",
    "    )\n",
    "    \n",
    "    explanations[case_type] = explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparing Explanations Across Different Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract top features contributing to a prediction\n",
    "def get_top_contributors(explanation, top_n=5):\n",
    "    \"\"\"\n",
    "    Get the top features contributing to a prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    explanation : dict\n",
    "        Explanation dictionary with SHAP values\n",
    "    top_n : int, optional\n",
    "        Number of top contributors to return\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with top contributing features\n",
    "    \"\"\"\n",
    "    # Get feature names and SHAP values\n",
    "    feature_names = explanation['instance'].columns\n",
    "    shap_values = explanation['shap_values'][0]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    contributors = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'SHAP Value': shap_values,\n",
    "        'Absolute Impact': np.abs(shap_values)\n",
    "    })\n",
    "    \n",
    "    # Add interpretable names if available\n",
    "    if feature_mapping:\n",
    "        contributors['Interpretable Name'] = contributors['Feature'].map(feature_mapping)\n",
    "    \n",
    "    # Sort by absolute impact\n",
    "    contributors = contributors.sort_values('Absolute Impact', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return contributors.head(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare top contributors across different cases\n",
    "for case_type, explanation in explanations.items():\n",
    "    # Get top contributors\n",
    "    top_contributors = get_top_contributors(explanation)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Top Contributors for {case_type} Prediction\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"True Label: {'Stroke' if explanation['true_label'] == 1 else 'No Stroke'}\")\n",
    "    print(f\"Predicted Label: {'Stroke' if explanation['prediction'] == 1 else 'No Stroke'}\")\n",
    "    if explanation['prediction_proba'] is not None:\n",
    "        print(f\"Predicted Probability: {explanation['prediction_proba']:.4f}\")\n",
    "    print(\"\\nTop Contributing Features:\")\n",
    "    print(top_contributors)\n",
    "    \n",
    "    # Create a horizontal bar plot of SHAP values\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Sort by SHAP value\n",
    "    top_contributors_sorted = top_contributors.sort_values('SHAP Value')\n",
    "    \n",
    "    # Plot bars\n",
    "    bars = plt.barh(\n",
    "        top_contributors_sorted['Interpretable Name'] if 'Interpretable Name' in top_contributors_sorted.columns else top_contributors_sorted['Feature'],\n",
    "        top_contributors_sorted['SHAP Value'],\n",
    "        color=['red' if x > 0 else 'blue' for x in top_contributors_sorted['SHAP Value']]\n",
    "    )\n",
    "    \n",
    "    # Add values to bars\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        label_x_pos = width if width > 0 else width - 0.05\n",
    "        plt.text(label_x_pos, bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.4f}', va='center', ha='left' if width > 0 else 'right')\n",
    "    \n",
    "    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.xlabel('SHAP Value (Impact on Prediction)', fontsize=12)\n",
    "    plt.title(f\"Top Features Impacting {case_type} Prediction\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/shap_explanations/top_contributors_{case_type.replace(\" \", \"_\").lower()}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Build an Interactive Stroke Risk Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to simulate stroke risk for different patient profiles\n",
    "def simulate_stroke_risk(age, hypertension, heart_disease, bmi, glucose_level, gender='Male', ever_married='Yes',\n",
    "                         work_type='Private', residence_type='Urban', smoking_status='never smoked'):\n",
    "    \"\"\"\n",
    "    Simulate stroke risk for a given patient profile.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    age : float\n",
    "        Patient age in years\n",
    "    hypertension : int\n",
    "        Whether the patient has hypertension (0=No, 1=Yes)\n",
    "    heart_disease : int\n",
    "        Whether the patient has heart disease (0=No, 1=Yes)\n",
    "    bmi : float\n",
    "        Body Mass Index\n",
    "    glucose_level : float\n",
    "        Average glucose level (mg/dL)\n",
    "    gender : str, optional\n",
    "        Patient gender ('Male' or 'Female')\n",
    "    ever_married : str, optional\n",
    "        Whether the patient was ever married ('Yes' or 'No')\n",
    "    work_type : str, optional\n",
    "        Type of work ('Private', 'Self-employed', 'Govt_job', 'children', 'Never_worked')\n",
    "    residence_type : str, optional\n",
    "        Type of residence ('Urban' or 'Rural')\n",
    "    smoking_status : str, optional\n",
    "        Smoking status ('never smoked', 'formerly smoked', 'smokes', 'Unknown')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with risk assessment and SHAP explanation\n",
    "    \"\"\"\n",
    "    # Create a DataFrame with the patient profile\n",
    "    # First, we'll create a patient profile with the same columns as df_interpretable\n",
    "    patient_data = pd.DataFrame({\n",
    "        'age': [age],\n",
    "        'hypertension': [hypertension],\n",
    "        'heart_disease': [heart_disease],\n",
    "        'bmi': [bmi],\n",
    "        'avg_glucose_level': [glucose_level],\n",
    "        'gender': [gender],\n",
    "        'ever_married': [ever_married],\n",
    "        'work_type': [work_type],\n",
    "        'Residence_type': [residence_type],\n",
    "        'smoking_status': [smoking_status]\n",
    "    })\n",
    "    \n",
    "    # Now we need to encode this in the same way as our model expects\n",
    "    # For simplicity, we'll load the one-hot encoder from the preprocessing notebook\n",
    "    # Since we don't have it here, we'll manually transform the data\n",
    "    \n",
    "    # Create a DataFrame with the same columns as X (encoded data)\n",
    "    encoded_patient = pd.DataFrame(np.zeros((1, len(X.columns))), columns=X.columns)\n",
    "    \n",
    "    # Set numerical features\n",
    "    encoded_patient['age'] = age\n",
    "    encoded_patient['bmi'] = bmi\n",
    "    encoded_patient['avg_glucose_level'] = glucose_level\n",
    "    encoded_patient['hypertension'] = hypertension\n",
    "    encoded_patient['heart_disease'] = heart_disease\n",
    "    \n",
    "    # Set categorical features\n",
    "    if gender == 'Male':\n",
    "        encoded_patient['gender_Male'] = 1\n",
    "        \n",
    "    if ever_married == 'Yes':\n",
    "        encoded_patient['ever_married_Yes'] = 1\n",
    "        \n",
    "    if residence_type == 'Urban':\n",
    "        encoded_patient['Residence_type_Urban'] = 1\n",
    "    \n",
    "    # Work type\n",
    "    if work_type in ['Private', 'Self-employed', 'children', 'Never_worked']:\n",
    "        encoded_patient[f'work_type_{work_type}'] = 1\n",
    "    \n",
    "    # Smoking status\n",
    "    if smoking_status in ['formerly smoked', 'never smoked', 'smokes']:\n",
    "        encoded_patient[f'smoking_status_{smoking_status}'] = 1\n",
    "    \n",
    "    # Fill in derived features based on business logic from preprocessing\n",
    "    # Age group\n",
    "    if age <= 18:\n",
    "        encoded_patient['age_group_0-18'] = 1\n",
    "    elif age <= 30:\n",
    "        encoded_patient['age_group_19-30'] = 1\n",
    "    elif age <= 40:\n",
    "        encoded_patient['age_group_31-40'] = 1\n",
    "    elif age <= 50:\n",
    "        encoded_patient['age_group_41-50'] = 1\n",
    "    elif age <= 60:\n",
    "        encoded_patient['age_group_51-60'] = 1\n",
    "    elif age <= 70:\n",
    "        encoded_patient['age_group_61-70'] = 1\n",
    "    elif age <= 80:\n",
    "        encoded_patient['age_group_71-80'] = 1\n",
    "    else:\n",
    "        encoded_patient['age_group_81+'] = 1\n",
    "    \n",
    "    # BMI category\n",
    "    if bmi < 18.5:\n",
    "        encoded_patient['bmi_category_Underweight'] = 1\n",
    "    elif bmi < 25:\n",
    "        encoded_patient['bmi_category_Normal'] = 1\n",
    "    elif bmi < 30:\n",
    "        encoded_patient['bmi_category_Overweight'] = 1\n",
    "    else:\n",
    "        encoded_patient['bmi_category_Obese'] = 1\n",
    "    \n",
    "    # Glucose category\n",
    "    if glucose_level < 70:\n",
    "        encoded_patient['glucose_category_Low'] = 1\n",
    "    elif glucose_level < 100:\n",
    "        encoded_patient['glucose_category_Normal'] = 1\n",
    "    elif glucose_level < 126:\n",
    "        encoded_patient['glucose_category_Prediabetes'] = 1\n",
    "    else:\n",
    "        encoded_patient['glucose_category_Diabetes'] = 1\n",
    "    \n",
    "    # Interaction features\n",
    "    encoded_patient['age_hypertension'] = age * hypertension\n",
    "    encoded_patient['age_heart_disease'] = age * heart_disease\n",
    "    encoded_patient['glucose_bmi'] = glucose_level * bmi\n",
    "    encoded_patient['is_senior'] = 1 if age >= 65 else 0\n",
    "    encoded_patient['comorbidity_None'] = 1 if (hypertension == 0 and heart_disease == 0) else 0\n",
    "    encoded_patient['comorbidity_One Condition'] = 1 if (hypertension + heart_disease == 1) else 0\n",
    "    encoded_patient['comorbidity_Both Conditions'] = 1 if (hypertension == 1 and heart_disease == 1) else 0\n",
    "    \n",
    "    # Scale numerical features\n",
    "    # First, make sure all columns from original X are in encoded_patient\n",
    "    for col in X.columns:\n",
    "        if col not in encoded_patient.columns:\n",
    "            encoded_patient[col] = 0\n",
    "    \n",
    "    # Ensure same column order as X\n",
    "    encoded_patient = encoded_patient[X.columns]\n",
    "    \n",
    "    # Scale features\n",
    "    scaled_patient = pd.DataFrame(scaler.transform(encoded_patient), columns=encoded_patient.columns)\n",
    "    \n",
    "    # Make prediction\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        risk_proba = model.predict_proba(scaled_patient)[0, 1]\n",
    "        risk_level = 1 if risk_proba >= 0.5 else 0\n",
    "    else:\n",
    "        risk_level = model.predict(scaled_patient)[0]\n",
    "        risk_proba = None\n",
    "    \n",
    "    # Get SHAP values\n",
    "    patient_shap_values = explainer.shap_values(scaled_patient)\n",
    "    if isinstance(patient_shap_values, list) and len(patient_shap_values) > 1:\n",
    "        patient_shap_class1 = patient_shap_values[1]\n",
    "        expected_value = explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value\n",
    "    else:\n",
    "        patient_shap_class1 = patient_shap_values\n",
    "        expected_value = explainer.expected_value\n",
    "    \n",
    "    # Get top contributing features\n",
    "    shap_df = pd.DataFrame({\n",
    "        'Feature': scaled_patient.columns,\n",
    "        'SHAP Value': patient_shap_class1[0],\n",
    "        'Absolute Value': np.abs(patient_shap_class1[0])\n",
    "    })\n",
    "    if feature_mapping:\n",
    "        shap_df['Interpretable Name'] = shap_df['Feature'].map(feature_mapping)\n",
    "    \n",
    "    # Sort by absolute impact\n",
    "    shap_df = shap_df.sort_values('Absolute Value', ascending=False).reset_index(drop=True)\n",
    "    top_factors = shap_df.head(5)\n",
    "    \n",
    "    # Prepare risk assessment\n",
    "    risk_assessment = {\n",
    "        'patient_profile': patient_data.iloc[0].to_dict(),\n",
    "        'risk_level': 'High' if risk_level == 1 else 'Low',\n",
    "        'risk_probability': risk_proba,\n",
    "        'top_risk_factors': top_factors,\n",
    "        'shap_values': patient_shap_class1,\n",
    "        'expected_value': expected_value,\n",
    "        'scaled_patient': scaled_patient\n",
    "    }\n",
    "    \n",
    "    # Display risk assessment\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STROKE RISK ASSESSMENT\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Patient Profile:\")\n",
    "    print(f\"  Age: {age}\")\n",
    "    print(f\"  Gender: {gender}\")\n",
    "    print(f\"  BMI: {bmi:.2f}\")\n",
    "    print(f\"  Glucose Level: {glucose_level:.2f} mg/dL\")\n",
    "    print(f\"  Hypertension: {'Yes' if hypertension == 1 else 'No'}\")\n",
    "    print(f\"  Heart Disease: {'Yes' if heart_disease == 1 else 'No'}\")\n",
    "    print(f\"  Smoking Status: {smoking_status}\")\n",
    "    print(f\"\\nRisk Assessment:\")\n",
    "    print(f\"  Risk Level: {risk_assessment['risk_level']}\")\n",
    "    if risk_proba is not None:\n",
    "        print(f\"  Risk Probability: {risk_proba:.2%}\")\n",
    "    \n",
    "    print(f\"\\nTop Risk Factors:\")\n",
    "    for i, (_, row) in enumerate(top_factors.iterrows(), 1):\n",
    "        feature_name = row['Interpretable Name'] if 'Interpretable Name' in row else row['Feature']\n",
    "        impact = 'Increases' if row['SHAP Value'] > 0 else 'Decreases'\n",
    "        print(f\"  {i}. {feature_name}: {impact} risk by {abs(row['SHAP Value']):.4f}\")\n",
    "    \n",
    "    # Create force plot\n",
    "    plt.figure(figsize=(20, 3))\n",
    "    shap.force_plot(expected_value, patient_shap_class1[0], scaled_patient.iloc[0], \n",
    "                   matplotlib=True, show=False)\n",
    "    plt.title(f\"SHAP Force Plot - Risk Factors\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/shap_explanations/simulated_patient_force_plot.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return risk_assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: High-risk patient profile\n",
    "high_risk_assessment = simulate_stroke_risk(\n",
    "    age=78,\n",
    "    hypertension=1,\n",
    "    heart_disease=1,\n",
    "    bmi=32.5,\n",
    "    glucose_level=190.5,\n",
    "    gender='Male',\n",
    "    smoking_status='formerly smoked'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Low-risk patient profile\n",
    "low_risk_assessment = simulate_stroke_risk(\n",
    "    age=35,\n",
    "    hypertension=0,\n",
    "    heart_disease=0,\n",
    "    bmi=24.8,\n",
    "    glucose_level=92.3,\n",
    "    gender='Female',\n",
    "    smoking_status='never smoked'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Moderate-risk patient profile\n",
    "moderate_risk_assessment = simulate_stroke_risk(\n",
    "    age=62,\n",
    "    hypertension=1,\n",
    "    heart_disease=0,\n",
    "    bmi=28.5,\n",
    "    glucose_level=145.3,\n",
    "    gender='Male',\n",
    "    smoking_status='smokes'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Key Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Global Model Insights\n",
    "\n",
    "Based on our SHAP analysis, we can draw the following key insights about stroke prediction:\n",
    "\n",
    "1. **Top Predictors**: The most important features for predicting stroke were:\n",
    "   - Age (especially being in older age groups)\n",
    "   - Hypertension status\n",
    "   - Glucose levels (especially diabetic levels)\n",
    "   - Heart disease status\n",
    "   - BMI (especially being obese)\n",
    "\n",
    "2. **Feature Relationships**:\n",
    "   - Age and hypertension show strong interactions - older patients with hypertension have substantially higher stroke risk\n",
    "   - Glucose levels become increasingly important as they rise above diabetic thresholds (>126 mg/dL)\n",
    "   - The presence of both hypertension and heart disease (comorbidity) dramatically increases stroke risk\n",
    "\n",
    "3. **Non-modifiable vs. Modifiable Risk Factors**:\n",
    "   - Non-modifiable: Age, gender\n",
    "   - Modifiable: Hypertension management, glucose control, BMI, smoking status\n",
    "\n",
    "### 9.2 Individual Risk Assessment\n",
    "\n",
    "Our SHAP-based risk assessment tool demonstrates how individual risk profiles can be explained:\n",
    "\n",
    "1. For high-risk patients, age is typically the strongest predictor, followed by comorbidities\n",
    "2. For low-risk patients, young age and absence of comorbidities contribute most to the low-risk assessment\n",
    "3. For moderate-risk patients, a mix of risk-increasing and risk-decreasing factors leads to a more nuanced prediction\n",
    "\n",
    "### 9.3 Clinical Applications\n",
    "\n",
    "These SHAP explanations could be valuable in clinical settings by:\n",
    "\n",
    "1. **Personalized Risk Communication**: Providing patients with clear visualizations of their personal risk factors\n",
    "2. **Intervention Planning**: Identifying which modifiable risk factors would most effectively reduce stroke risk\n",
    "3. **Clinical Decision Support**: Helping clinicians understand why the model made specific predictions\n",
    "4. **Educational Tool**: Teaching medical students and residents about stroke risk factors and their relative importance\n",
    "\n",
    "### 9.4 Future Directions\n",
    "\n",
    "To further enhance model explainability and clinical utility:\n",
    "\n",
    "1. Integrate the SHAP explanations into a user-friendly interface for clinical use\n",
    "2. Explore how interventions (e.g., reducing BMI or glucose levels) affect predicted stroke risk\n",
    "3. Combine SHAP explanations with existing clinical risk scores for validation\n",
    "4. Study how SHAP explanations affect patient understanding and behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Saving SHAP Explainer for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the SHAP explainer for deployment\n",
    "explainer_path = 'models/stroke_prediction_explainer.pkl'\n",
    "with open(explainer_path, 'wb') as f:\n",
    "    pickle.dump(explainer, f)\n",
    "print(f\"SHAP explainer saved to {explainer_path}\")\n",
    "\n",
    "# Save feature mapping for interpretation\n",
    "feature_mapping_path = 'models/feature_mapping.json'\n",
    "with open(feature_mapping_path, 'w') as f:\n",
    "    # Convert keys to strings for JSON serialization\n",
    "    mapping_str_keys = {str(k): v for k, v in feature_mapping.items()}\n",
    "    json.dump(mapping_str_keys, f, indent=4)\n",
    "print(f\"Feature mapping saved to {feature_mapping_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a utility function for generating explanations in deployment\n",
    "def generate_explanation(input_data, feature_names=None):\n",
    "    \"\"\"\n",
    "    Generate SHAP explanation for a prediction in a deployment setting.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_data : array-like\n",
    "        Input features (must be scaled and in the same format as during training)\n",
    "    feature_names : list, optional\n",
    "        Names of the features\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with explanation details\n",
    "    \"\"\"\n",
    "    # Load assets\n",
    "    with open('models/stroke_prediction_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    with open('models/stroke_prediction_explainer.pkl', 'rb') as f:\n",
    "        explainer = pickle.load(f)\n",
    "    \n",
    "    with open('models/feature_mapping.json', 'r') as f:\n",
    "        feature_mapping = json.load(f)\n",
    "    \n",
    "    # Convert input data to correct format if needed\n",
    "    if not isinstance(input_data, pd.DataFrame):\n",
    "        if feature_names is not None:\n",
    "            input_data = pd.DataFrame([input_data], columns=feature_names)\n",
    "        else:\n",
    "            input_data = pd.DataFrame([input_data])\n",
    "    \n",
    "    # Get prediction\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        pred_proba = model.predict_proba(input_data)[0, 1]\n",
    "        pred_class = int(pred_proba >= 0.5)\n",
    "    else:\n",
    "        pred_class = model.predict(input_data)[0]\n",
    "        pred_proba = None\n",
    "    \n",
    "    # Get SHAP values\n",
    "    shap_values = explainer.shap_values(input_data)\n",
    "    if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "        shap_values_class1 = shap_values[1]\n",
    "        expected_value = explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value\n",
    "    else:\n",
    "        shap_values_class1 = shap_values\n",
    "        expected_value = explainer.expected_value\n",
    "    \n",
    "    # Get top contributing features\n",
    "    feature_contribution = []\n",
    "    for i, col in enumerate(input_data.columns):\n",
    "        feature_contribution.append({\n",
    "            'feature': col,\n",
    "            'interpretable_name': feature_mapping.get(str(col), col),\n",
    "            'shap_value': float(shap_values_class1[0][i]),\n",
    "            'abs_value': float(abs(shap_values_class1[0][i]))\n",
    "        })\n",
    "    \n",
    "    # Sort by absolute contribution\n",
    "    feature_contribution.sort(key=lambda x: x['abs_value'], reverse=True)\n",
    "    \n",
    "    # Prepare explanation\n",
    "    explanation = {\n",
    "        'prediction': {\n",
    "            'class': pred_class,\n",
    "            'probability': pred_proba,\n",
    "            'label': 'Stroke' if pred_class == 1 else 'No Stroke'\n",
    "        },\n",
    "        'base_value': float(expected_value),\n",
    "        'feature_contribution': feature_contribution,\n",
    "        'top_contributors': feature_contribution[:5],\n",
    "        'risk_level': 'High' if pred_class == 1 else 'Low'\n",
    "    }\n",
    "    \n",
    "    return explanation\n",
    "\n",
    "# Save the utility function as a Python module\n",
    "with open('models/stroke_explainer_utils.py', 'w') as f:\n",
    "    f.write(\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def generate_explanation(input_data, feature_names=None):\n",
    "    \\\"\\\"\\\"\n",
    "    Generate SHAP explanation for a prediction in a deployment setting.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_data : array-like\n",
    "        Input features (must be scaled and in the same format as during training)\n",
    "    feature_names : list, optional\n",
    "        Names of the features\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with explanation details\n",
    "    \\\"\\\"\\\"\n",
    "    # Load assets\n",
    "    with open('models/stroke_prediction_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    with open('models/stroke_prediction_explainer.pkl', 'rb') as f:\n",
    "        explainer = pickle.load(f)\n",
    "    \n",
    "    with open('models/feature_mapping.json', 'r') as f:\n",
    "        feature_mapping = json.load(f)\n",
    "    \n",
    "    # Convert input data to correct format if needed\n",
    "    if not isinstance(input_data, pd.DataFrame):\n",
    "        if feature_names is not None:\n",
    "            input_data = pd.DataFrame([input_data], columns=feature_names)\n",
    "        else:\n",
    "            input_data = pd.DataFrame([input_data])\n",
    "    \n",
    "    # Get prediction\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        pred_proba = model.predict_proba(input_data)[0, 1]\n",
    "        pred_class = int(pred_proba >= 0.5)\n",
    "    else:\n",
    "        pred_class = model.predict(input_data)[0]\n",
    "        pred_proba = None\n",
    "    \n",
    "    # Get SHAP values\n",
    "    shap_values = explainer.shap_values(input_data)\n",
    "    if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "        shap_values_class1 = shap_values[1]\n",
    "        expected_value = explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value\n",
    "    else:\n",
    "        shap_values_class1 = shap_values\n",
    "        expected_value = explainer.expected_value\n",
    "    \n",
    "    # Get top contributing features\n",
    "    feature_contribution = []\n",
    "    for i, col in enumerate(input_data.columns):\n",
    "        feature_contribution.append({\n",
    "            'feature': col,\n",
    "            'interpretable_name': feature_mapping.get(str(col), col),\n",
    "            'shap_value': float(shap_values_class1[0][i]),\n",
    "            'abs_value': float(abs(shap_values_class1[0][i]))\n",
    "        })\n",
    "    \n",
    "    # Sort by absolute contribution\n",
    "    feature_contribution.sort(key=lambda x: x['abs_value'], reverse=True)\n",
    "    \n",
    "    # Prepare explanation\n",
    "    explanation = {\n",
    "        'prediction': {\n",
    "            'class': pred_class,\n",
    "            'probability': pred_proba,\n",
    "            'label': 'Stroke' if pred_class == 1 else 'No Stroke'\n",
    "        },\n",
    "        'base_value': float(expected_value),\n",
    "        'feature_contribution': feature_contribution,\n",
    "        'top_contributors': feature_contribution[:5],\n",
    "        'risk_level': 'High' if pred_class == 1 else 'Low'\n",
    "    }\n",
    "    \n",
    "    return explanation\n",
    "\"\"\")\n",
    "\n",
    "print(\"Utility function saved to models/stroke_explainer_utils.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated how to use SHAP to explain the predictions of our stroke prediction model. We've explored:\n",
    "\n",
    "1. **Global interpretability**: Understanding which features are most important across the dataset\n",
    "2. **Local interpretability**: Explaining individual predictions for specific patients\n",
    "3. **Feature interactions**: Visualizing how features interact to influence stroke risk\n",
    "4. **Risk simulation**: Creating a tool to simulate and explain stroke risk for different patient profiles\n",
    "\n",
    "These explainability techniques are essential for healthcare applications, where understanding model decisions is as important as the accuracy of those decisions. By leveraging SHAP, we've made our stroke prediction model more transparent and trustworthy, potentially increasing its utility in clinical settings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}