{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stroke Prediction: Data Preprocessing and EDA\n",
    "\n",
    "This notebook focuses on the following preprocessing steps:\n",
    "1. Loading and exploring the stroke dataset\n",
    "2. Visualizing key features and relationships\n",
    "3. Handling missing values with multiple imputation strategies\n",
    "4. Creating feature encodings and transformations\n",
    "5. Saving processed data for the modeling phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Specific libraries for preprocessing and imputation\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer # MICE\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Create directories for outputs\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "os.makedirs('figures', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "print(\"Data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "missing_data = pd.DataFrame({'Missing Values': missing_values, \n",
    "                            'Percentage': missing_percent})\n",
    "print(missing_data[missing_data['Missing Values'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical summary of numerical features:\")\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features summary\n",
    "print(\"Categorical features summary:\")\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for feature in categorical_features:\n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(df[feature].value_counts())\n",
    "    print(f\"Percentage:\\n{df[feature].value_counts(normalize=True) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution (target variable)\n",
    "print(\"Target variable distribution:\")\n",
    "print(df['stroke'].value_counts())\n",
    "print(f\"Percentage:\\n{df['stroke'].value_counts(normalize=True) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any unusual values or potential data quality issues\n",
    "print(\"Check for unusual values:\")\n",
    "for col in df.columns:\n",
    "    if df[col].dtype != 'object':\n",
    "        print(f\"{col}: Min={df[col].min()}, Max={df[col].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.countplot(x='stroke', data=df, palette='Set2')\n",
    "\n",
    "# Add count labels\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "plt.title('Stroke Distribution (Target Variable)', fontsize=15)\n",
    "plt.xlabel('Stroke (0=No, 1=Yes)', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.savefig('figures/stroke_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate class imbalance ratio\n",
    "imbalance_ratio = df['stroke'].value_counts()[0] / df['stroke'].value_counts()[1]\n",
    "print(f\"Class imbalance ratio (No:Yes): {imbalance_ratio:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore numerical features distribution\n",
    "numerical_features = ['age', 'avg_glucose_level', 'bmi']\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, feature in enumerate(numerical_features, 1):\n",
    "    # Distribution by stroke\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.histplot(data=df, x=feature, hue='stroke', kde=True, bins=30, alpha=0.6, element='step')\n",
    "    plt.title(f'{feature} Distribution by Stroke')\n",
    "    \n",
    "    # Boxplot by stroke\n",
    "    plt.subplot(3, 3, i+3)\n",
    "    sns.boxplot(x='stroke', y=feature, data=df, palette='Set2')\n",
    "    plt.title(f'{feature} by Stroke Status')\n",
    "    \n",
    "    # Violin plot\n",
    "    plt.subplot(3, 3, i+6)\n",
    "    sns.violinplot(x='stroke', y=feature, data=df, palette='Set2', inner='quartile')\n",
    "    plt.title(f'{feature} Distribution (Violin) by Stroke Status')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/numerical_features_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis between numerical features\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = df[numerical_features + ['stroke']].corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            linewidths=0.5, vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap of Numerical Features', fontsize=15)\n",
    "plt.savefig('figures/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot of numerical features by stroke status\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.pairplot(df[numerical_features + ['stroke']], hue='stroke', diag_kind='kde',\n",
    "             palette='Set2', height=2.5, aspect=1.2)\n",
    "plt.savefig('figures/pairplot_numerical_features.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features and their relation with stroke\n",
    "categorical_features = ['gender', 'hypertension', 'heart_disease', 'ever_married', \n",
    "                       'work_type', 'Residence_type', 'smoking_status']\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "for i, feature in enumerate(categorical_features, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    \n",
    "    # Calculate stroke percentage for each category\n",
    "    stroke_pct = df.groupby(feature)['stroke'].mean() * 100\n",
    "    counts = df[feature].value_counts()\n",
    "    \n",
    "    # Create a DataFrame for plotting\n",
    "    plot_df = pd.DataFrame({\n",
    "        'Category': stroke_pct.index,\n",
    "        'Stroke_Percentage': stroke_pct.values,\n",
    "        'Count': counts.values\n",
    "    })\n",
    "    \n",
    "    # Sort by stroke percentage\n",
    "    plot_df = plot_df.sort_values('Stroke_Percentage', ascending=False)\n",
    "    \n",
    "    # Bar plot\n",
    "    ax = sns.barplot(x='Category', y='Stroke_Percentage', data=plot_df, palette='coolwarm')\n",
    "    \n",
    "    # Add count labels\n",
    "    for j, p in enumerate(ax.patches):\n",
    "        ax.annotate(f'n={plot_df[\"Count\"].iloc[j]}', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height() + 0.3),\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.title(f'Stroke Rate by {feature}')\n",
    "    plt.ylabel('Stroke Percentage (%)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylim(0, max(plot_df['Stroke_Percentage']) * 1.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/categorical_features_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked bar plot for categorical features\n",
    "plt.figure(figsize=(20, 15))\n",
    "for i, feature in enumerate(categorical_features, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    \n",
    "    # Calculate proportions\n",
    "    props = df.groupby([feature, 'stroke']).size().unstack()\n",
    "    props = props.div(props.sum(axis=1), axis=0)\n",
    "    \n",
    "    # Plot\n",
    "    props.plot(kind='bar', stacked=True, ax=plt.gca(), \n",
    "               color=['#3498db', '#e74c3c'], width=0.8)\n",
    "    \n",
    "    plt.title(f'Stroke Distribution by {feature}')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.xlabel(feature)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(['No Stroke (0)', 'Stroke (1)'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/categorical_stacked_plots.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Age-specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create age groups\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 18, 30, 40, 50, 60, 70, 80, 100],\n",
    "                         labels=['0-18', '19-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81+'])\n",
    "\n",
    "# Analyze stroke rate by age group\n",
    "plt.figure(figsize=(12, 6))\n",
    "age_stroke = df.groupby('age_group')['stroke'].mean() * 100\n",
    "counts = df['age_group'].value_counts().sort_index()\n",
    "\n",
    "# Plot bar chart\n",
    "ax = sns.barplot(x=age_stroke.index, y=age_stroke.values, palette='rocket')\n",
    "\n",
    "# Add count labels\n",
    "for i, p in enumerate(ax.patches):\n",
    "    ax.annotate(f'n={counts.iloc[i]}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height() + 0.3),\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title('Stroke Rate by Age Group', fontsize=15)\n",
    "plt.xlabel('Age Group', fontsize=12)\n",
    "plt.ylabel('Stroke Percentage (%)', fontsize=12)\n",
    "plt.ylim(0, max(age_stroke.values) * 1.2)\n",
    "plt.savefig('figures/stroke_rate_by_age.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI vs Age with Stroke indication\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=df.dropna(subset=['bmi']), x='age', y='bmi', \n",
    "                hue='stroke', palette={0: '#3498db', 1: '#e74c3c'}, \n",
    "                size='stroke', sizes={0: 30, 1: 100}, alpha=0.7)\n",
    "\n",
    "plt.title('BMI vs Age with Stroke Indication', fontsize=15)\n",
    "plt.xlabel('Age', fontsize=12)\n",
    "plt.ylabel('BMI', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='Stroke', labels=['No', 'Yes'])\n",
    "plt.savefig('figures/bmi_vs_age.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glucose level vs Age with Stroke indication\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=df, x='age', y='avg_glucose_level', \n",
    "                hue='stroke', palette={0: '#3498db', 1: '#e74c3c'}, \n",
    "                size='stroke', sizes={0: 30, 1: 100}, alpha=0.7)\n",
    "\n",
    "plt.title('Glucose Level vs Age with Stroke Indication', fontsize=15)\n",
    "plt.xlabel('Age', fontsize=12)\n",
    "plt.ylabel('Average Glucose Level', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='Stroke', labels=['No', 'Yes'])\n",
    "plt.savefig('figures/glucose_vs_age.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Additional Analysis: Hypertension & Heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine hypertension and heart disease to analyze comorbidity\n",
    "df['comorbidity'] = df['hypertension'] + df['heart_disease']\n",
    "df['comorbidity'] = df['comorbidity'].map({0: 'None', 1: 'One Condition', 2: 'Both Conditions'})\n",
    "\n",
    "# Analyze stroke rate by comorbidity status\n",
    "plt.figure(figsize=(10, 6))\n",
    "comorbidity_stroke = df.groupby('comorbidity')['stroke'].mean() * 100\n",
    "counts = df['comorbidity'].value_counts().reindex(['None', 'One Condition', 'Both Conditions'])\n",
    "\n",
    "# Plot bar chart\n",
    "ax = sns.barplot(x=comorbidity_stroke.index, y=comorbidity_stroke.values, palette='YlOrRd')\n",
    "\n",
    "# Add count labels\n",
    "for i, p in enumerate(ax.patches):\n",
    "    ax.annotate(f'n={counts.iloc[i]}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height() + 0.3),\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title('Stroke Rate by Comorbidity Status', fontsize=15)\n",
    "plt.xlabel('Comorbidity Status', fontsize=12)\n",
    "plt.ylabel('Stroke Percentage (%)', fontsize=12)\n",
    "plt.ylim(0, max(comorbidity_stroke.values) * 1.2)\n",
    "plt.savefig('figures/stroke_rate_by_comorbidity.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe for feature engineering\n",
    "df_fe = df.copy()\n",
    "\n",
    "# Remove ID column as it doesn't provide predictive value\n",
    "df_fe = df_fe.drop('id', axis=1)\n",
    "\n",
    "# Create BMI categories based on standard ranges\n",
    "def categorize_bmi(bmi):\n",
    "    if pd.isna(bmi):\n",
    "        return np.nan\n",
    "    elif bmi < 18.5:\n",
    "        return 'Underweight'\n",
    "    elif bmi < 25:\n",
    "        return 'Normal'\n",
    "    elif bmi < 30:\n",
    "        return 'Overweight'\n",
    "    else:\n",
    "        return 'Obese'\n",
    "\n",
    "df_fe['bmi_category'] = df_fe['bmi'].apply(categorize_bmi)\n",
    "\n",
    "# Create glucose level categories\n",
    "def categorize_glucose(glucose):\n",
    "    if glucose < 70:\n",
    "        return 'Low'\n",
    "    elif glucose < 100:\n",
    "        return 'Normal'\n",
    "    elif glucose < 126:\n",
    "        return 'Prediabetes'\n",
    "    else:\n",
    "        return 'Diabetes'\n",
    "\n",
    "df_fe['glucose_category'] = df_fe['avg_glucose_level'].apply(categorize_glucose)\n",
    "\n",
    "# Create interaction features\n",
    "df_fe['age_hypertension'] = df_fe['age'] * df_fe['hypertension']\n",
    "df_fe['age_heart_disease'] = df_fe['age'] * df_fe['heart_disease']\n",
    "df_fe['glucose_bmi'] = df_fe['avg_glucose_level'] * df_fe['bmi']\n",
    "\n",
    "# Create a binary variable for senior citizens (age >= 65)\n",
    "df_fe['is_senior'] = (df_fe['age'] >= 65).astype(int)\n",
    "\n",
    "# Display new features\n",
    "print(\"New features added:\")\n",
    "print(df_fe[['bmi_category', 'glucose_category', 'age_hypertension', \n",
    "             'age_heart_disease', 'glucose_bmi', 'is_senior']].head())\n",
    "\n",
    "# Count of missing values in new features\n",
    "print(\"\\nMissing values in new features:\")\n",
    "print(df_fe[['bmi_category', 'glucose_category', 'age_hypertension', \n",
    "             'age_heart_disease', 'glucose_bmi', 'is_senior']].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handle Missing Values (BMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Analyze BMI Missing Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze missing BMI values pattern\n",
    "missing_bmi = df_fe['bmi'].isnull()\n",
    "print(f\"Number of records with missing BMI: {missing_bmi.sum()} ({missing_bmi.mean()*100:.2f}%)\")\n",
    "\n",
    "# Compare stroke rate in records with and without BMI\n",
    "stroke_rate_with_bmi = df_fe[~missing_bmi]['stroke'].mean() * 100\n",
    "stroke_rate_without_bmi = df_fe[missing_bmi]['stroke'].mean() * 100\n",
    "\n",
    "print(f\"Stroke rate in records with BMI: {stroke_rate_with_bmi:.2f}%\")\n",
    "print(f\"Stroke rate in records without BMI: {stroke_rate_without_bmi:.2f}%\")\n",
    "\n",
    "# Visualize comparison of other features between records with and without BMI\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Age distribution by BMI missing status\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(data=df_fe, x='age', hue=missing_bmi, kde=True, \n",
    "             common_norm=False, palette=['#3498db', '#e74c3c'])\n",
    "plt.title('Age Distribution by BMI Missing Status')\n",
    "plt.legend(['BMI Present', 'BMI Missing'])\n",
    "\n",
    "# Glucose distribution by BMI missing status\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(data=df_fe, x='avg_glucose_level', hue=missing_bmi, kde=True, \n",
    "             common_norm=False, palette=['#3498db', '#e74c3c'])\n",
    "plt.title('Glucose Distribution by BMI Missing Status')\n",
    "plt.legend(['BMI Present', 'BMI Missing'])\n",
    "\n",
    "# Gender distribution by BMI missing status\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.countplot(data=df_fe, x='gender', hue=missing_bmi, palette=['#3498db', '#e74c3c'])\n",
    "plt.title('Gender Distribution by BMI Missing Status')\n",
    "plt.legend(['BMI Present', 'BMI Missing'])\n",
    "\n",
    "# Stroke distribution by BMI missing status\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.countplot(data=df_fe, x='stroke', hue=missing_bmi, palette=['#3498db', '#e74c3c'])\n",
    "plt.title('Stroke Distribution by BMI Missing Status')\n",
    "plt.legend(['BMI Present', 'BMI Missing'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/bmi_missing_pattern.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Implement Multiple Imputation Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies for different imputation methods\n",
    "df_mean = df_fe.copy()  # Simple mean imputation\n",
    "df_mice = df_fe.copy()  # MICE imputation\n",
    "df_age_group = df_fe.copy()  # Age-group based imputation\n",
    "\n",
    "# 1. Simple Mean Imputation\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "df_mean['bmi'] = mean_imputer.fit_transform(df_mean[['bmi']])\n",
    "print(\"1. Mean Imputation - Completed\")\n",
    "print(f\"   BMI mean after imputation: {df_mean['bmi'].mean():.2f}\")\n",
    "\n",
    "# 2. MICE (Multiple Imputation by Chained Equations)\n",
    "# Prepare data for MICE\n",
    "mice_features = ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi']\n",
    "mice_data = df_mice[mice_features].copy()\n",
    "\n",
    "# Convert categorical features to binary for imputation\n",
    "mice_categorical = df_mice[['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']]\n",
    "mice_categorical_encoded = pd.get_dummies(mice_categorical, drop_first=True)\n",
    "mice_data_full = pd.concat([mice_data, mice_categorical_encoded], axis=1)\n",
    "\n",
    "# Apply MICE imputation\n",
    "mice_imputer = IterativeImputer(estimator=LinearRegression(), \n",
    "                               random_state=42, \n",
    "                               max_iter=10, \n",
    "                               verbose=0)\n",
    "mice_imputed = mice_imputer.fit_transform(mice_data_full)\n",
    "\n",
    "# Update BMI values\n",
    "df_mice['bmi'] = mice_imputed[:, mice_data_full.columns.get_loc('bmi')]\n",
    "print(\"2. MICE Imputation - Completed\")\n",
    "print(f\"   BMI mean after imputation: {df_mice['bmi'].mean():.2f}\")\n",
    "\n",
    "# 3. Age-group based imputation\n",
    "# Calculate median BMI by age group\n",
    "age_group_bmi_median = df_age_group.groupby('age_group')['bmi'].median()\n",
    "print(\"\\nMedian BMI by age group:\")\n",
    "print(age_group_bmi_median)\n",
    "\n",
    "# Impute based on age group\n",
    "for age_group in age_group_bmi_median.index:\n",
    "    mask = (df_age_group['age_group'] == age_group) & (df_age_group['bmi'].isna())\n",
    "    df_age_group.loc[mask, 'bmi'] = age_group_bmi_median[age_group]\n",
    "    \n",
    "# If any missing values remain (e.g., if an age group had all NaN values)\n",
    "if df_age_group['bmi'].isna().any():\n",
    "    df_age_group['bmi'] = df_age_group['bmi'].fillna(df_age_group['bmi'].median())\n",
    "    \n",
    "print(\"3. Age-group Imputation - Completed\")\n",
    "print(f\"   BMI mean after imputation: {df_age_group['bmi'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. KNN Imputation as an additional method\n",
    "df_knn = df_fe.copy()\n",
    "\n",
    "# Prepare data for KNN imputation\n",
    "knn_features = ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi']\n",
    "knn_data = df_knn[knn_features].copy()\n",
    "\n",
    "# Normalize numerical features for KNN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "knn_data_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(knn_data.fillna(knn_data.median())),\n",
    "    columns=knn_data.columns\n",
    ")\n",
    "\n",
    "# Apply KNN imputation\n",
    "knn_imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "knn_imputed = knn_imputer.fit_transform(knn_data_scaled)\n",
    "\n",
    "# Inverse transform to get original scale\n",
    "knn_imputed_original = scaler.inverse_transform(knn_imputed)\n",
    "\n",
    "# Update BMI values\n",
    "df_knn['bmi'] = knn_imputed_original[:, knn_data.columns.get_loc('bmi')]\n",
    "print(\"4. KNN Imputation - Completed\")\n",
    "print(f\"   BMI mean after imputation: {df_knn['bmi'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare imputation methods\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Original distribution (excluding NaN)\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(df_fe['bmi'].dropna(), kde=True, color='#3498db')\n",
    "plt.axvline(df_fe['bmi'].dropna().mean(), color='r', linestyle='--')\n",
    "plt.title(f'Original BMI Distribution (Mean: {df_fe[\"bmi\"].dropna().mean():.2f})')\n",
    "\n",
    "# Mean imputation\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(df_mean['bmi'], kde=True, color='#2ecc71')\n",
    "plt.axvline(df_mean['bmi'].mean(), color='r', linestyle='--')\n",
    "plt.title(f'Mean Imputation (Mean: {df_mean[\"bmi\"].mean():.2f})')\n",
    "\n",
    "# MICE imputation\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(df_mice['bmi'], kde=True, color='#e74c3c')\n",
    "plt.axvline(df_mice['bmi'].mean(), color='r', linestyle='--')\n",
    "plt.title(f'MICE Imputation (Mean: {df_mice[\"bmi\"].mean():.2f})')\n",
    "\n",
    "# KNN imputation\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(df_knn['bmi'], kde=True, color='#9b59b6')\n",
    "plt.axvline(df_knn['bmi'].mean(), color='r', linestyle='--')\n",
    "plt.title(f'KNN Imputation (Mean: {df_knn[\"bmi\"].mean():.2f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/bmi_imputation_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare imputation methods by age group\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Calculate mean BMI by age group for each imputation method\n",
    "original_bmi_by_age = df_fe.groupby('age_group')['bmi'].mean()\n",
    "mean_bmi_by_age = df_mean.groupby('age_group')['bmi'].mean()\n",
    "mice_bmi_by_age = df_mice.groupby('age_group')['bmi'].mean()\n",
    "knn_bmi_by_age = df_knn.groupby('age_group')['bmi'].mean()\n",
    "age_group_bmi_by_age = df_age_group.groupby('age_group')['bmi'].mean()\n",
    "\n",
    "# Create dataframe for plotting\n",
    "bmi_comparison = pd.DataFrame({\n",
    "    'Original': original_bmi_by_age,\n",
    "    'Mean Imputation': mean_bmi_by_age,\n",
    "    'MICE Imputation': mice_bmi_by_age,\n",
    "    'KNN Imputation': knn_bmi_by_age,\n",
    "    'Age-Group Imputation': age_group_bmi_by_age\n",
    "})\n",
    "\n",
    "# Plot\n",
    "bmi_comparison.plot(kind='bar', figsize=(15, 8))\n",
    "plt.title('Average BMI by Age Group Across Imputation Methods', fontsize=15)\n",
    "plt.xlabel('Age Group', fontsize=12)\n",
    "plt.ylabel('Average BMI', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='Imputation Method')\n",
    "plt.savefig('figures/bmi_imputation_by_age.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how well each imputation method preserves the relationship with other variables\n",
    "plt.figure(figsize=(15, 20))\n",
    "\n",
    "# BMI vs Age\n",
    "plt.subplot(4, 2, 1)\n",
    "sns.scatterplot(data=df_fe.dropna(subset=['bmi']), x='age', y='bmi', alpha=0.5, label='Original', color='#3498db')\n",
    "plt.title('Original BMI vs Age')\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "mask = df_fe['bmi'].isna()\n",
    "sns.scatterplot(data=df_mice[mask], x='age', y='bmi', alpha=0.5, label='MICE Imputed', color='#e74c3c')\n",
    "sns.scatterplot(data=df_knn[mask], x='age', y='bmi', alpha=0.5, label='KNN Imputed', color='#9b59b6')\n",
    "sns.scatterplot(data=df_age_group[mask], x='age', y='bmi', alpha=0.5, label='Age-Group Imputed', color='#2ecc71')\n",
    "plt.title('Imputed BMI vs Age (Missing Values Only)')\n",
    "\n",
    "# BMI vs Glucose\n",
    "plt.subplot(4, 2, 3)\n",
    "sns.scatterplot(data=df_fe.dropna(subset=['bmi']), x='avg_glucose_level', y='bmi', alpha=0.5, label='Original', color='#3498db')\n",
    "plt.title('Original BMI vs Glucose')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "sns.scatterplot(data=df_mice[mask], x='avg_glucose_level', y='bmi', alpha=0.5, label='MICE Imputed', color='#e74c3c')\n",
    "sns.scatterplot(data=df_knn[mask], x='avg_glucose_level', y='bmi', alpha=0.5, label='KNN Imputed', color='#9b59b6')\n",
    "sns.scatterplot(data=df_age_group[mask], x='avg_glucose_level', y='bmi', alpha=0.5, label='Age-Group Imputed', color='#2ecc71')\n",
    "plt.title('Imputed BMI vs Glucose (Missing Values Only)')\n",
    "\n",
    "# BMI vs Hypertension\n",
    "plt.subplot(4, 2, 5)\n",
    "sns.boxplot(data=df_fe.dropna(subset=['bmi']), x='hypertension', y='bmi', palette='Set2')\n",
    "plt.title('Original BMI by Hypertension')\n",
    "\n",
    "plt.subplot(4, 2, 6)\n",
    "boxplot_data = pd.melt(pd.DataFrame({\n",
    "    'hypertension': df_fe.loc[mask, 'hypertension'],\n",
    "    'MICE': df_mice.loc[mask, 'bmi'],\n",
    "    'KNN': df_knn.loc[mask, 'bmi'],\n",
    "    'Age-Group': df_age_group.loc[mask, 'bmi']\n",
    "}), id_vars=['hypertension'], var_name='Method', value_name='BMI')\n",
    "sns.boxplot(data=boxplot_data, x='hypertension', y='BMI', hue='Method', palette='Dark2')\n",
    "plt.title('Imputed BMI by Hypertension (Missing Values Only)')\n",
    "\n",
    "# BMI vs Heart Disease\n",
    "plt.subplot(4, 2, 7)\n",
    "sns.boxplot(data=df_fe.dropna(subset=['bmi']), x='heart_disease', y='bmi', palette='Set2')\n",
    "plt.title('Original BMI by Heart Disease')\n",
    "\n",
    "plt.subplot(4, 2, 8)\n",
    "boxplot_data = pd.melt(pd.DataFrame({\n",
    "    'heart_disease': df_fe.loc[mask, 'heart_disease'],\n",
    "    'MICE': df_mice.loc[mask, 'bmi'],\n",
    "    'KNN': df_knn.loc[mask, 'bmi'],\n",
    "    'Age-Group': df_age_group.loc[mask, 'bmi']\n",
    "}), id_vars=['heart_disease'], var_name='Method', value_name='BMI')\n",
    "sns.boxplot(data=boxplot_data, x='heart_disease', y='BMI', hue='Method', palette='Dark2')\n",
    "plt.title('Imputed BMI by Heart Disease (Missing Values Only)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/bmi_imputation_relationships.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Select Best Imputation Method for Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on evaluation of imputation methods, select the best approach\n",
    "# For this example, we'll choose MICE imputation as it typically preserves relationships best\n",
    "# In a real scenario, you might want to compare these methods based on model performance\n",
    "\n",
    "# Create final dataset with MICE imputation for BMI\n",
    "df_final = df_mice.copy()\n",
    "\n",
    "# Update the bmi_category after imputation\n",
    "df_final['bmi_category'] = df_final['bmi'].apply(categorize_bmi)\n",
    "\n",
    "# Update the glucose_bmi interaction feature\n",
    "df_final['glucose_bmi'] = df_final['avg_glucose_level'] * df_final['bmi']\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(\"Missing values in final dataset:\")\n",
    "print(df_final.isnull().sum())\n",
    "\n",
    "# Show summary statistics of the final dataset\n",
    "print(\"\\nSummary statistics for numerical features:\")\n",
    "print(df_final[['age', 'avg_glucose_level', 'bmi']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical features\n",
    "categorical_cols = ['gender', 'ever_married', 'work_type', 'Residence_type', \n",
    "                    'smoking_status', 'bmi_category', 'glucose_category', 'age_group']\n",
    "\n",
    "# Apply one-hot encoding\n",
    "df_encoded = pd.get_dummies(df_final, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Show the new columns created\n",
    "print(f\"Original dataset columns: {len(df_final.columns)}\")\n",
    "print(f\"Encoded dataset columns: {len(df_encoded.columns)}\")\n",
    "\n",
    "# Display first few rows of encoded dataset\n",
    "print(\"\\nFirst 5 rows of encoded dataset:\")\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed datasets\n",
    "\n",
    "# 1. Save the dataset with basic preprocessing but without encoding\n",
    "# This is useful for further model-specific preprocessing\n",
    "df_final.to_csv('data/processed/stroke_dataset_processed.csv', index=False)\n",
    "print(f\"Saved processed dataset with {df_final.shape[1]} columns to 'data/processed/stroke_dataset_processed.csv'\")\n",
    "\n",
    "# 2. Save the fully processed dataset with encoding\n",
    "# This is ready for modeling\n",
    "df_encoded.to_csv('data/processed/stroke_dataset_encoded.csv', index=False)\n",
    "print(f\"Saved encoded dataset with {df_encoded.shape[1]} columns to 'data/processed/stroke_dataset_encoded.csv'\")\n",
    "\n",
    "# 3. Save a version specifically for EDA\n",
    "df_eda = df_final.copy()\n",
    "df_eda.to_csv('data/processed/stroke_dataset_eda.csv', index=False)\n",
    "print(f\"Saved EDA dataset to 'data/processed/stroke_dataset_eda.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary of Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary of preprocessing steps\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"1. Dataset Information:\")\n",
    "print(f\"   - Original shape: {df.shape}\")\n",
    "print(f\"   - Processed shape: {df_final.shape}\")\n",
    "print(f\"   - Encoded shape: {df_encoded.shape}\")\n",
    "\n",
    "print(\"\\n2. Missing Values:\")\n",
    "print(f\"   - Original missing BMI values: {df['bmi'].isna().sum()} ({df['bmi'].isna().mean()*100:.2f}%)\")\n",
    "print(f\"   - Imputation method used: MICE (Multiple Imputation by Chained Equations)\")\n",
    "print(f\"   - Final missing values: {df_final.isna().sum().sum()}\")\n",
    "\n",
    "print(\"\\n3. Class Distribution:\")\n",
    "print(f\"   - Negative class (No Stroke): {df_final['stroke'].value_counts()[0]} ({df_final['stroke'].value_counts(normalize=True)[0]*100:.2f}%)\")\n",
    "print(f\"   - Positive class (Stroke): {df_final['stroke'].value_counts()[1]} ({df_final['stroke'].value_counts(normalize=True)[1]*100:.2f}%)\")\n",
    "print(f\"   - Class imbalance ratio: {df_final['stroke'].value_counts()[0]/df_final['stroke'].value_counts()[1]:.2f}:1\")\n",
    "\n",
    "print(\"\\n4. Feature Engineering:\")\n",
    "print(f\"   - Original features: {len(df.columns)}\")\n",
    "print(f\"   - Added features: {len(df_final.columns) - len(df.columns) + 1}\")\n",
    "print(f\"   - Key added features: bmi_category, glucose_category, age_group, comorbidity, age_hypertension, etc.\")\n",
    "\n",
    "print(\"\\n5. Categorical Encoding:\")\n",
    "print(f\"   - Categorical columns encoded: {len(categorical_cols)}\")\n",
    "print(f\"   - Total features after encoding: {len(df_encoded.columns)}\")\n",
    "\n",
    "print(\"\\n6. Output Files:\")\n",
    "print(\"   - data/processed/stroke_dataset_processed.csv (Processed without encoding)\")\n",
    "print(\"   - data/processed/stroke_dataset_encoded.csv (Processed with encoding)\")\n",
    "print(\"   - data/processed/stroke_dataset_eda.csv (For EDA purposes)\")\n",
    "\n",
    "print(\"\\nPreprocessing completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
