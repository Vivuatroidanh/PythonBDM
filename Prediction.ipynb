{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# The libraries used in processing the dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import imblearn as ib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# The dataframe is read from the csv file - healthcare-dataset-stroke-data.csv - taken from kaggle\n",
    "df = pd.read_csv(\"healthcare-dataset-stroke-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# The first 5 instances of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Printing the number of N/A values in eacg column\n",
    "print(df.isna().sum())\n",
    "# Graphical representation of the na values present in the attribute - bar graph\n",
    "df.isna().sum().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# To check the  statistical analysis of all numerical type attributes  (count, mean, standaard deviation, minimum values, all quartiles, maximum values)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Provides the data type of all attributes and the number of NOT NULL values count is obtained\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# The 'id' column is dropped since the attribute holds no significant importance to the problem at hand\n",
    "df = df.drop(['id'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Checking the values in the gender column\n",
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Removing the 'other' gender instance inorder to reduce the dimension\n",
    "df['gender'] = df['gender'].replace('Other','Female')\n",
    "# plotting a pie chart to see the gender count distribution\n",
    "df['gender'].value_counts().plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Value count in the stroke attribute\n",
    "df['stroke'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Graphical representation of the value count distribution of the target attribute\n",
    "df['stroke'].value_counts().plot(kind=\"bar\",color = \"cyan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"% of people who actualy got a stroke : \",(df['stroke'].value_counts()[1]/df['stroke'].value_counts().sum()).round(3)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Graphical representation of the value counts of the hypertension attribute\n",
    "df['hypertension'].value_counts().plot(kind=\"bar\",color = \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Value of count of work-type attribute\n",
    "df['work_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Graphical representation of the value counts of the work-type attribute\n",
    "df['work_type'].value_counts().plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Value of count of somoking status attribute\n",
    "df['smoking_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Graphical representation of the value counts of the smoking staus attribute\n",
    "df['smoking_status'].value_counts().plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Value of count of residence attribute\n",
    "df['Residence_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Graphical representation of the value counts of the residence attribute\n",
    "df['Residence_type'].value_counts().plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Number of BMI - NULL values\n",
    "df['bmi'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Graphical representation of bmi attribute\n",
    "sns.histplot(data=df['bmi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the count of outliers based on those instances which are out of iqr \n",
    "Q1 = df['bmi'].quantile(0.25)\n",
    "Q3 = df['bmi'].quantile(0.75)\n",
    "# Finding IQR\n",
    "IQR = Q3 - Q1\n",
    "da=(df['bmi'] < (Q1 - 1.5 * IQR)) | (df['bmi'] > (Q3 + 1.5 * IQR))\n",
    "da.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Percentage of NULL values in bmi\n",
    "df['bmi'].isna().sum()/len(df['bmi'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_na=df.loc[df['bmi'].isnull()]\n",
    "g=df_na['stroke'].sum()\n",
    "print(\"People who got stroke and their BMI is NA:\",g)\n",
    "h=df['stroke'].sum()\n",
    "print(\"People who got stroke and their BMI is given:\",h)\n",
    "print(\"percentage of people with stroke in Nan values to the overall dataset:\",g/h*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Percentage of instances who got stroke\n",
    "df['stroke'].sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Analysing whether to drop NA values in Bmi column\n",
    "df_na=df.loc[df['bmi'].isnull()]\n",
    "print(\"Nan BMI values where people have stroke:\",df_na['stroke'].sum())\n",
    "print(\"overall BMI values where people have stroke:\",df['stroke'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Imputing the missing N/A values using the median of bmi column\n",
    "print(\"median of bmi\",df['bmi'].median())\n",
    "df['bmi']=df['bmi'].fillna(df['bmi'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Graphical representation fo the data in age column\n",
    "# histogram\n",
    "sns.histplot(data=df['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# boxplot\n",
    "sns.boxplot(data=df['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Graphical representation fo the data in glucose level column\n",
    "# histogram\n",
    "sns.histplot(data=df['avg_glucose_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "sns.boxplot(data=df['avg_glucose_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the count of outliers based on those instances which are out of iqr \n",
    "Q1 = df['avg_glucose_level'].quantile(0.25)\n",
    "Q3 = df['avg_glucose_level'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "da=(df['avg_glucose_level'] < (Q1 - 1.5 * IQR)) | (df['avg_glucose_level'] > (Q3 + 1.5 * IQR))\n",
    "da.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Correlation matrix between the attributes in the dataset to find if any attributes are correlated\n",
    "corrmat=df.corr()\n",
    "f,ax=plt.subplots(figsize=(9,8))\n",
    "sns.heatmap(corrmat,ax=ax,cmap=\"YlGnBu\",linewidth=0.8,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Value count of heart disease attribute\n",
    "df['heart_disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df['heart_disease'].value_counts().plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Value count of evver married attribute\n",
    "df['ever_married'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Graphical representation\n",
    "df['ever_married'].value_counts().plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Comparing stroke with gender\n",
    "sns.countplot(x='stroke', hue='gender', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Comparing stroke with work-type\n",
    "sns.countplot(x='stroke', hue='work_type', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Comparing stroke with somking_status\n",
    "sns.countplot(x='stroke', hue='smoking_status', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Comparing stroke with residence type\n",
    "sns.countplot(x='stroke', hue='Residence_type', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Comparing stroke with heart disease\n",
    "sns.countplot(x='stroke', hue='heart_disease', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Comparing stroke with married status\n",
    "sns.countplot(x='stroke', hue='ever_married', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Converting numeric-binary value attributes to string\n",
    "df[['hypertension', 'heart_disease', 'stroke']] = df[['hypertension', 'heart_disease', 'stroke']].astype(str)\n",
    "# Generating dummy attributes - one hot encoding format\n",
    "df = pd.get_dummies(df, drop_first= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# The data frame after performing dummy attributes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Since our Dataset is highly undersampled (based on target instances) we are going to perform a over sampling method to have equal representation of both the target classes\n",
    "# Using random oversampling - importing the library \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Performing a minority oversampling\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X=df.drop(['stroke_1'],axis=1)\n",
    "y=df['stroke_1']\n",
    "\n",
    "# Obtaining the oversampled dataframes - testing and training\n",
    "X_over, y_over = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# importing a scaling modeule\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Since the numeric attributes in the dataset is in different ranges and three are outliers persent we are usign a scaler to get all the values into the same range.\n",
    "s = StandardScaler()\n",
    "# Scaling the numeric attributes\n",
    "df[['bmi', 'avg_glucose_level', 'age']] = s.fit_transform(df[['bmi', 'avg_glucose_level', 'age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# creating dataset split for training and testing the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Performing a 80-20 test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size= 0.20, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Checking the size of the splits \n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#importing the Decision Tree Classifier module\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Libraries for calculating performance metrics\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import auc,roc_auc_score,roc_curve,precision_score,recall_score,f1_score\n",
    "\n",
    "# Create the classifier object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Training the classifier\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#predicting result using the test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Printing the accuracyof the model\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#importing the KNN Classifier module\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Libraries for calculating performance metrics\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "from sklearn.metrics import auc,roc_auc_score,roc_curve,precision_score,recall_score,f1_score\n",
    "\n",
    "# Create the classifier object\n",
    "# 2 neighbours because of the 2 classes\n",
    "knn = KNeighborsClassifier(n_neighbors = 2)\n",
    "# Training the classifier\n",
    "knn.fit(X_train,y_train)\n",
    "#predicting result using the test dataset\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_prob_knn = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Printing the accuracy and roc-auc score of the model\n",
    "confusion_matrix(y_test, y_pred_knn)\n",
    "print('Accuracy:',accuracy_score(y_test, y_pred_knn))\n",
    "print('ROC AUC Score:', roc_auc_score(y_test, y_pred_prob_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#importing the XGBoost Classifier module\n",
    "from xgboost  import XGBClassifier\n",
    "\n",
    "# Create the classifier object\n",
    "xgb = XGBClassifier()\n",
    "# Training the classifier\n",
    "xgb.fit(X_train,y_train)\n",
    "#predicting result using the test dataset\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "y_pred_prob_xgb = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Printing the accuracy and roc-auc score of the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_xgb))\n",
    "print('ROC AUC Score:', roc_auc_score(y_test, y_pred_prob_xgb))\n",
    "\n",
    "# plots of roc_auc \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_xgb)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, linewidth=2, color= 'teal')\n",
    "plt.plot([0,1], [0,1], 'r--' )\n",
    "plt.title('ROC Curve of XGBOOST')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix of the model\n",
    "from sklearn.metrics import plot_confusion_matrix,precision_recall_fscore_support\n",
    "plot_confusion_matrix(xgb,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Printing the precision,recall,f1score and support values of the model based on the confusion matrix\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "print(\"Accuracy_score:\",accuracy_score(y_test,y_pred_xgb))\n",
    "print(\"Precision_score:\",precision_score(y_test,y_pred_xgb))\n",
    "print(\"Recall_score:\",recall_score(y_test,y_pred_xgb))\n",
    "print(\"f1_score:\",f1_score(y_test,y_pred_xgb))\n",
    "print('ROC AUC Score:', roc_auc_score(y_test, y_pred_prob_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# importing random forest classifier module for training\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the classifier object\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# Train the model using the training sets\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# performing predictions on the test dataset\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Printing accuracy of the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Importing module for kfold cross validation\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Performing k fold cross validation using 20 splits\n",
    "kfold_kridge = model_selection.KFold(n_splits=20, shuffle=True)\n",
    "results_kfold = model_selection.cross_val_score(rf_clf, X_over, y_over, cv=kfold_kridge)\n",
    "print(\"Accuracy: \", results_kfold.mean()*100)\n",
    "print(results_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix,precision_recall_fscore_support\n",
    "plot_confusion_matrix(rf_clf,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = classifier.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred_lr)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Making sample predictions based on manual value entry\n",
    "age=75\n",
    "avg_glucose_level=300\n",
    "bmi=36.6\n",
    "gender_Male=1\n",
    "ever_married_Yes=1\t\n",
    "work_type_Never_worked=0\t\n",
    "work_type_Private=1\t\n",
    "work_type_Self_employed=0\n",
    "work_type_children=0\t\n",
    "Residence_type_Urban=1\n",
    "smoking_status_formerly_smoked=1\n",
    "smoking_status_never_smoked=0\n",
    "smoking_status_smokes=0\n",
    "hypertension_1=1\n",
    "heart_disease_1=1\n",
    "input_features = [age\t,avg_glucose_level,\tbmi\t,gender_Male,hypertension_1,\theart_disease_1,ever_married_Yes,\twork_type_Never_worked,\twork_type_Private,\twork_type_Self_employed,\twork_type_children\t,Residence_type_Urban,\tsmoking_status_formerly_smoked,smoking_status_never_smoked\t,smoking_status_smokes]\n",
    "\n",
    "features_value = [np.array(input_features)]\n",
    "features_name = ['age'\t,'avg_glucose_level',\t'bmi'\t,'gender_Male'\t,'hypertension_1',\t'heart_disease_1','ever_married_Yes',\t'work_type_Never_worked',\t'work_type_Private',\t'work_type_Self-employed',\t'work_type_children'\t,'Residence_type_Urban',\t'smoking_status_formerly smoked','smoking_status_never smoked'\t,'smoking_status_smokes']\n",
    "\n",
    "df = pd.DataFrame(features_value, columns=features_name)\n",
    "prediction = rf_clf.predict(df)[0]\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# For the front end \n",
    "import pickle\n",
    "\n",
    "with open('model.pickle','wb') as f:\n",
    "  pickle.dump(rf_clf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Stroke Prediction Model Training and Evaluation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "\n",
    "# For metrics\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                           roc_auc_score, confusion_matrix, classification_report, \n",
    "                           plot_confusion_matrix, roc_curve, precision_recall_curve)\n",
    "\n",
    "# For models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                            AdaBoostClassifier, VotingClassifier, StackingClassifier)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# For imbalanced data\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "# For reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def load_data(file_path=\"healthcare-dataset-stroke-data.csv\"):\n",
    "    \"\"\"Load and preprocess the stroke dataset\"\"\"\n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Drop ID column\n",
    "    if 'id' in df.columns:\n",
    "        df = df.drop('id', axis=1)\n",
    "    \n",
    "    # Handle missing BMI values\n",
    "    if 'bmi' in df.columns and df['bmi'].isnull().sum() > 0:\n",
    "        print(f\"Handling {df['bmi'].isnull().sum()} missing BMI values using median imputation\")\n",
    "        df['bmi'] = df['bmi'].fillna(df['bmi'].median())\n",
    "    \n",
    "    # Handle 'Other' gender\n",
    "    if 'gender' in df.columns:\n",
    "        df['gender'] = df['gender'].replace('Other', 'Female')\n",
    "    \n",
    "    # Convert binary features to string for one-hot encoding\n",
    "    if 'stroke' in df.columns:\n",
    "        binary_features = ['hypertension', 'heart_disease', 'stroke']\n",
    "        df[binary_features] = df[binary_features].astype(str)\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "    \n",
    "    # Split into features and target\n",
    "    if 'stroke_1' in df_encoded.columns:\n",
    "        X = df_encoded.drop('stroke_1', axis=1)\n",
    "        y = df_encoded['stroke_1']\n",
    "    else:\n",
    "        X = df_encoded.drop('stroke', axis=1)\n",
    "        y = df_encoded['stroke']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def split_and_scale_data(X, y, test_size=0.2):\n",
    "    \"\"\"Split data into train/test sets and scale features\"\"\"\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train),\n",
    "        columns=X_train.columns\n",
    "    )\n",
    "    X_test_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_test),\n",
    "        columns=X_test.columns\n",
    "    )\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "\n",
    "def handle_imbalance(X_train, y_train, method='smote'):\n",
    "    \"\"\"Handle imbalanced data using SMOTE or random oversampling\"\"\"\n",
    "    print(f\"Class distribution before resampling: {np.bincount(y_train.astype(int))}\")\n",
    "    \n",
    "    if method == 'smote':\n",
    "        resampler = SMOTE(random_state=RANDOM_STATE)\n",
    "    elif method == 'random':\n",
    "        resampler = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    X_resampled, y_resampled = resampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    print(f\"Class distribution after resampling: {np.bincount(y_resampled.astype(int))}\")\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def create_models():\n",
    "    \"\"\"Create a dictionary of models to evaluate\"\"\"\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE),\n",
    "        'LightGBM': LGBMClassifier(random_state=RANDOM_STATE),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "    }\n",
    "    \n",
    "    return models\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Train and evaluate a model, returning evaluation metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Get probabilities if available\n",
    "    try:\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        has_proba = True\n",
    "    except:\n",
    "        y_pred_proba = None\n",
    "        has_proba = False\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    if has_proba:\n",
    "        metrics['roc_auc'] = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    \n",
    "    if has_proba:\n",
    "        print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    # Return the metrics and predictions for further analysis\n",
    "    return metrics, y_pred, y_pred_proba if has_proba else None, model\n",
    "\n",
    "def plot_confusion_matrix_custom(y_test, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"Plot confusion matrix for a model\"\"\"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve_custom(y_test, y_pred_proba, model_name=\"Model\"):\n",
    "    \"\"\"Plot ROC curve for a model\"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {model_name}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def create_voting_ensemble(models_dict, X_train, y_train, voting='soft'):\n",
    "    \"\"\"Create a voting ensemble from trained models\"\"\"\n",
    "    # Create a list of (name, model) tuples for VotingClassifier\n",
    "    estimators = []\n",
    "    \n",
    "    for name, (_, _, _, model) in models_dict.items():\n",
    "        estimators.append((name, model))\n",
    "    \n",
    "    # Create and train the voting ensemble\n",
    "    ensemble = VotingClassifier(estimators=estimators, voting=voting)\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "def create_stacking_ensemble(models_dict, X_train, y_train):\n",
    "    \"\"\"Create a stacking ensemble from trained models\"\"\"\n",
    "    # Create a list of (name, model) tuples for StackingClassifier\n",
    "    estimators = []\n",
    "    \n",
    "    for name, (_, _, _, model) in models_dict.items():\n",
    "        estimators.append((name, model))\n",
    "    \n",
    "    # Create and train the stacking ensemble\n",
    "    ensemble = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=LogisticRegression(max_iter=1000),\n",
    "        cv=5\n",
    "    )\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "def find_best_model(models_metrics):\n",
    "    \"\"\"Find the best model based on F1 score\"\"\"\n",
    "    best_model_name = max(models_metrics.items(), key=lambda x: x[1][0]['f1'])[0]\n",
    "    best_metrics, _, _, best_model = models_metrics[best_model_name]\n",
    "    \n",
    "    print(f\"\\nBest model: {best_model_name}\")\n",
    "    print(f\"F1 Score: {best_metrics['f1']:.4f}\")\n",
    "    print(f\"Precision: {best_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {best_metrics['recall']:.4f}\")\n",
    "    \n",
    "    if 'roc_auc' in best_metrics:\n",
    "        print(f\"ROC AUC: {best_metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    return best_model_name, best_model\n",
    "\n",
    "def save_model(model, filepath=\"best_stroke_model.pickle\"):\n",
    "    \"\"\"Save the model to a file\"\"\"\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    print(f\"Model saved to {filepath}\")\n",
    "\n",
    "def plot_feature_importance(model, feature_names, top_n=20):\n",
    "    \"\"\"Plot feature importance for tree-based models\"\"\"\n",
    "    if not hasattr(model, 'feature_importances_'):\n",
    "        print(\"This model doesn't have feature_importances_ attribute.\")\n",
    "        return\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    # Select top N features\n",
    "    n_features = min(top_n, len(feature_names))\n",
    "    top_indices = indices[:n_features]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(\"Feature Importances\", fontsize=16)\n",
    "    plt.bar(range(n_features), importances[top_indices], align=\"center\")\n",
    "    plt.xticks(range(n_features), [feature_names[i] for i in top_indices], rotation=90)\n",
    "    plt.xlim([-1, n_features])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def predict_sample(model, scaler, features, feature_names):\n",
    "    \"\"\"Predict stroke risk for a sample\"\"\"\n",
    "    # Create a DataFrame with the features\n",
    "    sample = pd.DataFrame([features], columns=feature_names)\n",
    "    \n",
    "    # Scale numerical features if needed\n",
    "    sample_scaled = scaler.transform(sample)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(sample_scaled)[0]\n",
    "    \n",
    "    # Get probability if available\n",
    "    try:\n",
    "        probability = model.predict_proba(sample_scaled)[0, 1]\n",
    "        has_proba = True\n",
    "    except:\n",
    "        probability = None\n",
    "        has_proba = False\n",
    "    \n",
    "    # Print prediction\n",
    "    print(\"\\nPrediction:\")\n",
    "    if prediction == 1:\n",
    "        print(\"⚠️ HIGH RISK OF STROKE DETECTED ⚠️\")\n",
    "    else:\n",
    "        print(\"✓ Low risk of stroke\")\n",
    "    \n",
    "    if has_proba:\n",
    "        print(f\"Probability of stroke: {probability:.2%}\")\n",
    "    \n",
    "    return prediction, probability if has_proba else None\n",
    "\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    X, y = load_data()\n",
    "    \n",
    "    # Split and scale data\n",
    "    print(\"\\nSplitting and scaling data...\")\n",
    "    X_train, X_test, y_train, y_test, scaler = split_and_scale_data(X, y)\n",
    "    \n",
    "    # Handle imbalanced data\n",
    "    print(\"\\nHandling imbalanced data...\")\n",
    "    X_train_resampled, y_train_resampled = handle_imbalance(X_train, y_train, method='smote')\n",
    "    \n",
    "    # Create models\n",
    "    print(\"\\nCreating models...\")\n",
    "    models = create_models()\n",
    "    \n",
    "    # Evaluate models\n",
    "    model_results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        metrics, y_pred, y_pred_proba, trained_model = evaluate_model(\n",
    "            model, X_train_resampled, X_test, y_train_resampled, y_test, name\n",
    "        )\n",
    "        model_results[name] = (metrics, y_pred, y_pred_proba, trained_model)\n",
    "        \n",
    "        # Plot confusion matrix and ROC curve if available\n",
    "        plot_confusion_matrix_custom(y_test, y_pred, name)\n",
    "        \n",
    "        if y_pred_proba is not None:\n",
    "            plot_roc_curve_custom(y_test, y_pred_proba, name)\n",
    "    \n",
    "    # Create voting ensemble\n",
    "    print(\"\\nCreating voting ensemble...\")\n",
    "    voting_ensemble = create_voting_ensemble(model_results, X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Evaluate voting ensemble\n",
    "    voting_metrics, voting_pred, voting_proba, _ = evaluate_model(\n",
    "        voting_ensemble, X_train_resampled, X_test, y_train_resampled, y_test, \"Voting Ensemble\"\n",
    "    )\n",
    "    model_results[\"Voting Ensemble\"] = (voting_metrics, voting_pred, voting_proba, voting_ensemble)\n",
    "    \n",
    "    # Plot confusion matrix and ROC curve for voting ensemble\n",
    "    plot_confusion_matrix_custom(y_test, voting_pred, \"Voting Ensemble\")\n",
    "    \n",
    "    if voting_proba is not None:\n",
    "        plot_roc_curve_custom(y_test, voting_proba, \"Voting Ensemble\")\n",
    "    \n",
    "    # Create stacking ensemble\n",
    "    print(\"\\nCreating stacking ensemble...\")\n",
    "    stacking_ensemble = create_stacking_ensemble(model_results, X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Evaluate stacking ensemble\n",
    "    stacking_metrics, stacking_pred, stacking_proba, _ = evaluate_model(\n",
    "        stacking_ensemble, X_train_resampled, X_test, y_train_resampled, y_test, \"Stacking Ensemble\"\n",
    "    )\n",
    "    model_results[\"Stacking Ensemble\"] = (stacking_metrics, stacking_pred, stacking_proba, stacking_ensemble)\n",
    "    \n",
    "    # Plot confusion matrix and ROC curve for stacking ensemble\n",
    "    plot_confusion_matrix_custom(y_test, stacking_pred, \"Stacking Ensemble\")\n",
    "    \n",
    "    if stacking_proba is not None:\n",
    "        plot_roc_curve_custom(y_test, stacking_proba, \"Stacking Ensemble\")\n",
    "    \n",
    "    # Find best model\n",
    "    best_model_name, best_model = find_best_model(model_results)\n",
    "    \n",
    "    # Plot feature importance for the best model if it's a tree-based model\n",
    "    if best_model_name in [\"Random Forest\", \"Gradient Boosting\", \"XGBoost\", \"LightGBM\"]:\n",
    "        plot_feature_importance(best_model, X.columns.tolist())\n",
    "    \n",
    "    # Save the best model\n",
    "    save_model(best_model)\n",
    "    \n",
    "    # Also save the scaler for later use\n",
    "    with open('stroke_model_scaler.pickle', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    print(\"\\nModel training and evaluation completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
