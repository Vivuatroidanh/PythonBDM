{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Stroke Exploratory Data Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def load_data(file_path=\"healthcare-dataset-stroke-data.csv\"):\n",
    "    \"\"\"Load the stroke dataset\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "def analyze_basic_info(df):\n",
    "    \"\"\"Display basic information about the dataset\"\"\"\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"\\nData types and non-null counts:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\nBasic statistics:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    print(\"\\nMissing values:\")\n",
    "    print(df.isna().sum())\n",
    "\n",
    "def analyze_target_distribution(df):\n",
    "    \"\"\"Analyze the distribution of the stroke target variable\"\"\"\n",
    "    stroke_count = df['stroke'].value_counts()\n",
    "    print(\"\\nStroke distribution:\")\n",
    "    print(stroke_count)\n",
    "    \n",
    "    stroke_percentage = 100 * df['stroke'].value_counts(normalize=True)\n",
    "    print(f\"\\n% of people who actually got a stroke: {stroke_percentage[1]:.3f}%\")\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(x='stroke', data=df, palette='viridis')\n",
    "    plt.title('Stroke Distribution')\n",
    "    plt.xlabel('Stroke (0=No, 1=Yes)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_missing_values(df):\n",
    "    \"\"\"Analyze missing values in the dataset\"\"\"\n",
    "    missing = df.isna().sum()\n",
    "    \n",
    "    if missing.sum() > 0:\n",
    "        print(\"\\nMissing values per column:\")\n",
    "        print(missing[missing > 0])\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        missing.plot.barh()\n",
    "        plt.title('Missing Values')\n",
    "        plt.xlabel('Count')\n",
    "        plt.ylabel('Column')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Specific analysis for BMI missing values\n",
    "        if 'bmi' in df.columns and df['bmi'].isna().sum() > 0:\n",
    "            df_na = df.loc[df['bmi'].isnull()]\n",
    "            stroke_in_na = df_na['stroke'].sum()\n",
    "            print(f\"People who got stroke and their BMI is NA: {stroke_in_na}\")\n",
    "            print(f\"Overall people who got stroke: {df['stroke'].sum()}\")\n",
    "            print(f\"Percentage of people with stroke in NaN values: {100 * stroke_in_na / df['stroke'].sum():.2f}%\")\n",
    "            \n",
    "            missing_percentage = 100 * df['bmi'].isna().sum() / len(df)\n",
    "            print(f\"NULL values hold {missing_percentage:.2f}% of the instances in the dataframe\")\n",
    "\n",
    "def analyze_numerical_features(df):\n",
    "    \"\"\"Analyze numerical features\"\"\"\n",
    "    numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    \n",
    "    for col in numerical_cols:\n",
    "        if col != 'id':  # Skip id column\n",
    "            plt.figure(figsize=(12, 5))\n",
    "            \n",
    "            # Histogram\n",
    "            plt.subplot(1, 2, 1)\n",
    "            sns.histplot(df[col], kde=True)\n",
    "            plt.title(f'Distribution of {col}')\n",
    "            \n",
    "            # Boxplot\n",
    "            plt.subplot(1, 2, 2)\n",
    "            sns.boxplot(data=df[col])\n",
    "            plt.title(f'Boxplot of {col}')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # If there are outliers, detect and count them\n",
    "            if col in ['bmi', 'avg_glucose_level', 'age']:\n",
    "                Q1 = df[col].quantile(0.25)\n",
    "                Q3 = df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                outliers = ((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR)))\n",
    "                outlier_count = outliers.sum()\n",
    "                print(f\"Total outliers in {col}: {outlier_count}\")\n",
    "                print(f\"Total non-outliers in {col}: {len(df) - outlier_count}\")\n",
    "\n",
    "def analyze_categorical_features(df):\n",
    "    \"\"\"Analyze categorical features\"\"\"\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        value_counts = df[col].value_counts()\n",
    "        print(f\"\\n{col} value counts:\")\n",
    "        print(value_counts)\n",
    "        \n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Bar chart\n",
    "        plt.subplot(1, 2, 1)\n",
    "        value_counts.plot(kind='bar', color='skyblue')\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Pie chart\n",
    "        plt.subplot(1, 2, 2)\n",
    "        value_counts.plot(kind='pie', autopct='%1.1f%%')\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.ylabel('')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def analyze_correlation(df):\n",
    "    \"\"\"Analyze correlation between numerical features\"\"\"\n",
    "    numerical_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "    \n",
    "    # Drop id column if it exists\n",
    "    if 'id' in numerical_df.columns:\n",
    "        numerical_df = numerical_df.drop('id', axis=1)\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = numerical_df.corr()\n",
    "    \n",
    "    # Plot correlation matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_feature_relationships_with_target(df):\n",
    "    \"\"\"Analyze relationships between features and the stroke target\"\"\"\n",
    "    # Numerical features vs target\n",
    "    numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    numerical_cols = [col for col in numerical_cols if col not in ['id', 'stroke']]\n",
    "    \n",
    "    for col in numerical_cols:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(x='stroke', y=col, data=df)\n",
    "        plt.title(f'{col} by Stroke')\n",
    "        plt.xlabel('Stroke (0=No, 1=Yes)')\n",
    "        plt.ylabel(col)\n",
    "        plt.show()\n",
    "    \n",
    "    # Categorical features vs target\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Cross-tabulation\n",
    "        cross_tab = pd.crosstab(df[col], df['stroke'], normalize='index')\n",
    "        cross_tab = cross_tab * 100  # Convert to percentage\n",
    "        \n",
    "        # Bar plot\n",
    "        cross_tab.plot(kind='bar', stacked=True)\n",
    "        plt.title(f'Percentage of Stroke by {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Percentage')\n",
    "        plt.legend(title='Stroke', labels=['No', 'Yes'])\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Add text annotations\n",
    "        for i, p in enumerate(plt.gca().patches):\n",
    "            width, height = p.get_width(), p.get_height()\n",
    "            x, y = p.get_xy() \n",
    "            if height > 5:  # Only annotate if percentage is greater than 5%\n",
    "                plt.gca().text(x+width/2, y+height/2, f'{height:.1f}%', \n",
    "                               ha='center', va='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Count plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.countplot(x=col, hue='stroke', data=df)\n",
    "        plt.title(f'Stroke Count by {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(title='Stroke', labels=['No', 'Yes'])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Basic preprocessing of the dataset\"\"\"\n",
    "    # Make a copy to avoid modifying the original dataframe\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Drop ID column\n",
    "    if 'id' in data.columns:\n",
    "        data = data.drop('id', axis=1)\n",
    "    \n",
    "    # Handle missing BMI values\n",
    "    if 'bmi' in data.columns and data['bmi'].isnull().sum() > 0:\n",
    "        data['bmi'] = data['bmi'].fillna(data['bmi'].median())\n",
    "    \n",
    "    # Handle 'Other' gender\n",
    "    if 'gender' in data.columns:\n",
    "        data['gender'] = data['gender'].replace('Other', 'Female')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    # Load the dataset\n",
    "    df = load_data()\n",
    "    \n",
    "    # Basic information\n",
    "    analyze_basic_info(df)\n",
    "    \n",
    "    # Target distribution\n",
    "    analyze_target_distribution(df)\n",
    "    \n",
    "    # Missing values\n",
    "    analyze_missing_values(df)\n",
    "    \n",
    "    # Preprocess data\n",
    "    df_processed = preprocess_data(df)\n",
    "    \n",
    "    # Analyze numerical features\n",
    "    analyze_numerical_features(df_processed)\n",
    "    \n",
    "    # Analyze categorical features\n",
    "    analyze_categorical_features(df_processed)\n",
    "    \n",
    "    # Correlation analysis\n",
    "    analyze_correlation(df_processed)\n",
    "    \n",
    "    # Feature relationships with target\n",
    "    analyze_feature_relationships_with_target(df_processed)\n",
    "    \n",
    "    print(\"\\nExploratory Data Analysis completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
