{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Stroke Prediction Model Training and Evaluation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "\n",
    "# For metrics\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                           roc_auc_score, confusion_matrix, classification_report, \n",
    "                           ConfusionMatrixDisplay, roc_curve, precision_recall_curve)\n",
    "\n",
    "# For models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                            AdaBoostClassifier, VotingClassifier, StackingClassifier)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# For imbalanced data\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "# For reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def load_data(file_path=\"healthcare-dataset-stroke-data.csv\"):\n",
    "    \"\"\"Load and preprocess the stroke dataset\"\"\"\n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Drop ID column\n",
    "    if 'id' in df.columns:\n",
    "        df = df.drop('id', axis=1)\n",
    "    \n",
    "    # Handle missing BMI values\n",
    "    if 'bmi' in df.columns and df['bmi'].isnull().sum() > 0:\n",
    "        print(f\"Handling {df['bmi'].isnull().sum()} missing BMI values using median imputation\")\n",
    "        df['bmi'] = df['bmi'].fillna(df['bmi'].median())\n",
    "    \n",
    "    # Handle 'Other' gender\n",
    "    if 'gender' in df.columns:\n",
    "        df['gender'] = df['gender'].replace('Other', 'Female')\n",
    "    \n",
    "    # Convert binary features to string for one-hot encoding\n",
    "    if 'stroke' in df.columns:\n",
    "        binary_features = ['hypertension', 'heart_disease', 'stroke']\n",
    "        df[binary_features] = df[binary_features].astype(str)\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "    \n",
    "    # Split into features and target\n",
    "    if 'stroke_1' in df_encoded.columns:\n",
    "        X = df_encoded.drop('stroke_1', axis=1)\n",
    "        y = df_encoded['stroke_1']\n",
    "    else:\n",
    "        X = df_encoded.drop('stroke', axis=1)\n",
    "        y = df_encoded['stroke']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def split_and_scale_data(X, y, test_size=0.2):\n",
    "    \"\"\"Split data into train/test sets and scale features\"\"\"\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train),\n",
    "        columns=X_train.columns\n",
    "    )\n",
    "    X_test_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_test),\n",
    "        columns=X_test.columns\n",
    "    )\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "\n",
    "def handle_imbalance(X_train, y_train, method='smote'):\n",
    "    \"\"\"Handle imbalanced data using SMOTE or random oversampling\"\"\"\n",
    "    print(f\"Class distribution before resampling: {np.bincount(y_train.astype(int))}\")\n",
    "    \n",
    "    if method == 'smote':\n",
    "        resampler = SMOTE(random_state=RANDOM_STATE)\n",
    "    elif method == 'random':\n",
    "        resampler = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    X_resampled, y_resampled = resampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    print(f\"Class distribution after resampling: {np.bincount(y_resampled.astype(int))}\")\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def create_models():\n",
    "    \"\"\"Create a dictionary of models to evaluate\"\"\"\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE),\n",
    "        'LightGBM': LGBMClassifier(random_state=RANDOM_STATE),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "    }\n",
    "    \n",
    "    return models\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Train and evaluate a model, returning evaluation metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Get probabilities if available\n",
    "    try:\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        has_proba = True\n",
    "    except:\n",
    "        y_pred_proba = None\n",
    "        has_proba = False\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    if has_proba:\n",
    "        metrics['roc_auc'] = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    \n",
    "    if has_proba:\n",
    "        print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    # Return the metrics and predictions for further analysis\n",
    "    return metrics, y_pred, y_pred_proba if has_proba else None, model\n",
    "\n",
    "def plot_confusion_matrix_custom(y_test, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"Plot confusion matrix for a model using ConfusionMatrixDisplay\"\"\"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Create ConfusionMatrixDisplay manually\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Stroke', 'Stroke'])\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    disp.plot(cmap='Blues', values_format='d')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve_custom(y_test, y_pred_proba, model_name=\"Model\"):\n",
    "    \"\"\"Plot ROC curve for a model\"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {model_name}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def create_voting_ensemble(models_dict, X_train, y_train, voting='soft'):\n",
    "    \"\"\"Create a voting ensemble from trained models\"\"\"\n",
    "    # Create a list of (name, model) tuples for VotingClassifier\n",
    "    estimators = []\n",
    "    \n",
    "    for name, (_, _, _, model) in models_dict.items():\n",
    "        estimators.append((name, model))\n",
    "    \n",
    "    # Create and train the voting ensemble\n",
    "    ensemble = VotingClassifier(estimators=estimators, voting=voting)\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "def create_stacking_ensemble(models_dict, X_train, y_train):\n",
    "    \"\"\"Create a stacking ensemble from trained models\"\"\"\n",
    "    # Create a list of (name, model) tuples for StackingClassifier\n",
    "    estimators = []\n",
    "    \n",
    "    for name, (_, _, _, model) in models_dict.items():\n",
    "        estimators.append((name, model))\n",
    "    \n",
    "    # Create and train the stacking ensemble\n",
    "    ensemble = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=LogisticRegression(max_iter=1000),\n",
    "        cv=5\n",
    "    )\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "def find_best_model(models_metrics):\n",
    "    \"\"\"Find the best model based on F1 score\"\"\"\n",
    "    best_model_name = max(models_metrics.items(), key=lambda x: x[1][0]['f1'])[0]\n",
    "    best_metrics, _, _, best_model = models_metrics[best_model_name]\n",
    "    \n",
    "    print(f\"\\nBest model: {best_model_name}\")\n",
    "    print(f\"F1 Score: {best_metrics['f1']:.4f}\")\n",
    "    print(f\"Precision: {best_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {best_metrics['recall']:.4f}\")\n",
    "    \n",
    "    if 'roc_auc' in best_metrics:\n",
    "        print(f\"ROC AUC: {best_metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    return best_model_name, best_model\n",
    "\n",
    "def save_model(model, filepath=\"best_stroke_model.pickle\"):\n",
    "    \"\"\"Save the model to a file\"\"\"\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    print(f\"Model saved to {filepath}\")\n",
    "\n",
    "def plot_feature_importance(model, feature_names, top_n=20):\n",
    "    \"\"\"Plot feature importance for tree-based models\"\"\"\n",
    "    if not hasattr(model, 'feature_importances_'):\n",
    "        print(\"This model doesn't have feature_importances_ attribute.\")\n",
    "        return\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    # Select top N features\n",
    "    n_features = min(top_n, len(feature_names))\n",
    "    top_indices = indices[:n_features]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(\"Feature Importances\", fontsize=16)\n",
    "    plt.bar(range(n_features), importances[top_indices], align=\"center\")\n",
    "    plt.xticks(range(n_features), [feature_names[i] for i in top_indices], rotation=90)\n",
    "    plt.xlim([-1, n_features])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def predict_sample(model, scaler, features, feature_names):\n",
    "    \"\"\"Predict stroke risk for a sample\"\"\"\n",
    "    # Create a DataFrame with the features\n",
    "    sample = pd.DataFrame([features], columns=feature_names)\n",
    "    \n",
    "    # Scale numerical features if needed\n",
    "    sample_scaled = scaler.transform(sample)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(sample_scaled)[0]\n",
    "    \n",
    "    # Get probability if available\n",
    "    try:\n",
    "        probability = model.predict_proba(sample_scaled)[0, 1]\n",
    "        has_proba = True\n",
    "    except:\n",
    "        probability = None\n",
    "        has_proba = False\n",
    "    \n",
    "    # Print prediction\n",
    "    print(\"\\nPrediction:\")\n",
    "    if prediction == 1:\n",
    "        print(\"⚠️ HIGH RISK OF STROKE DETECTED ⚠️\")\n",
    "    else:\n",
    "        print(\"✓ Low risk of stroke\")\n",
    "    \n",
    "    if has_proba:\n",
    "        print(f\"Probability of stroke: {probability:.2%}\")\n",
    "    \n",
    "    return prediction, probability if has_proba else None\n",
    "\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    X, y = load_data()\n",
    "    \n",
    "    # Split and scale data\n",
    "    print(\"\\nSplitting and scaling data...\")\n",
    "    X_train, X_test, y_train, y_test, scaler = split_and_scale_data(X, y)\n",
    "    \n",
    "    # Handle imbalanced data\n",
    "    print(\"\\nHandling imbalanced data...\")\n",
    "    X_train_resampled, y_train_resampled = handle_imbalance(X_train, y_train, method='smote')\n",
    "    \n",
    "    # Create models\n",
    "    print(\"\\nCreating models...\")\n",
    "    models = create_models()\n",
    "    \n",
    "    # Evaluate models\n",
    "    model_results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        metrics, y_pred, y_pred_proba, trained_model = evaluate_model(\n",
    "            model, X_train_resampled, X_test, y_train_resampled, y_test, name\n",
    "        )\n",
    "        model_results[name] = (metrics, y_pred, y_pred_proba, trained_model)\n",
    "        \n",
    "        # Plot confusion matrix and ROC curve if available\n",
    "        plot_confusion_matrix_custom(y_test, y_pred, name)\n",
    "        \n",
    "        if y_pred_proba is not None:\n",
    "            plot_roc_curve_custom(y_test, y_pred_proba, name)\n",
    "    \n",
    "    # Create voting ensemble\n",
    "    print(\"\\nCreating voting ensemble...\")\n",
    "    voting_ensemble = create_voting_ensemble(model_results, X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Evaluate voting ensemble\n",
    "    voting_metrics, voting_pred, voting_proba, _ = evaluate_model(\n",
    "        voting_ensemble, X_train_resampled, X_test, y_train_resampled, y_test, \"Voting Ensemble\"\n",
    "    )\n",
    "    model_results[\"Voting Ensemble\"] = (voting_metrics, voting_pred, voting_proba, voting_ensemble)\n",
    "    \n",
    "    # Plot confusion matrix and ROC curve for voting ensemble\n",
    "    plot_confusion_matrix_custom(y_test, voting_pred, \"Voting Ensemble\")\n",
    "    \n",
    "    if voting_proba is not None:\n",
    "        plot_roc_curve_custom(y_test, voting_proba, \"Voting Ensemble\")\n",
    "    \n",
    "    # Create stacking ensemble\n",
    "    print(\"\\nCreating stacking ensemble...\")\n",
    "    stacking_ensemble = create_stacking_ensemble(model_results, X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Evaluate stacking ensemble\n",
    "    stacking_metrics, stacking_pred, stacking_proba, _ = evaluate_model(\n",
    "        stacking_ensemble, X_train_resampled, X_test, y_train_resampled, y_test, \"Stacking Ensemble\"\n",
    "    )\n",
    "    model_results[\"Stacking Ensemble\"] = (stacking_metrics, stacking_pred, stacking_proba, stacking_ensemble)\n",
    "    \n",
    "    # Plot confusion matrix and ROC curve for stacking ensemble\n",
    "    plot_confusion_matrix_custom(y_test, stacking_pred, \"Stacking Ensemble\")\n",
    "    \n",
    "    if stacking_proba is not None:\n",
    "        plot_roc_curve_custom(y_test, stacking_proba, \"Stacking Ensemble\")\n",
    "    \n",
    "    # Find best model\n",
    "    best_model_name, best_model = find_best_model(model_results)\n",
    "    \n",
    "    # Plot feature importance for the best model if it's a tree-based model\n",
    "    if best_model_name in [\"Random Forest\", \"Gradient Boosting\", \"XGBoost\", \"LightGBM\"]:\n",
    "        plot_feature_importance(best_model, X.columns.tolist())\n",
    "    \n",
    "    # Save the best model\n",
    "    save_model(best_model)\n",
    "    \n",
    "    # Also save the scaler for later use\n",
    "    with open('stroke_model_scaler.pickle', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    print(\"\\nModel training and evaluation completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
